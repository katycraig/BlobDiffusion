\documentclass[11pt,leqno]{amsart}


\usepackage{amsthm,amsfonts,amsmath, amscd, amssymb, hyperref}
\usepackage{fullpage}
\usepackage[pdftex]{graphicx}
\usepackage{enumerate}
\usepackage{cite}
\usepackage[usenames,dvipsnames]{color}
\usepackage{subcaption}

\allowdisplaybreaks


\newtheorem{thm}{THEOREM}[section]
\newtheorem{lem}[thm]{LEMMA}
\newtheorem{cor}[thm]{COROLLARY}
\newtheorem{prop}[thm]{PROPOSITION}
\newtheorem{as}[thm]{ASSUMPTION}
\newtheorem{conjecture}[thm]{Conjecture}
\newtheorem{claim}[thm]{CLAIM}
\newtheorem{hyp}{HYPOTHESIS}

\theoremstyle{definition}
\newtheorem{defi}[thm]{DEFINITION}
\newtheorem{remark}[thm]{REMARK}
\newtheorem{fact}[thm]{Fact}
\newtheorem{ex}[thm]{Example}


\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bes}{\begin{equation*}}
\newcommand{\ees}{\end{equation*}}
\newcommand{\ul}[1]{\underline{\smash{{#1}}}}
\newcommand{\mt}[1]{\mathrm{#1}}
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand{\comment}[1]{{\color{red}#1}} % To mark comments
\newcommand{\kcomment}[1]{{\color{Aquamarine}#1}} % To mark comments


\newcommand{\R}{{\mathord{\mathbb R}}}
%\newcommand{\Rn}{{\mathord{\mathbb R}^n}}
\newcommand{\Rd}{{\mathord{\mathbb R}^d}}
\newcommand{\Zd}{{\mathord{\mathbb Z}^d}}
\newcommand{\N}{{\mathord{\mathbb N}}}
%\newcommand{\Lip}{{\rm Lip}}
\newcommand{\loc}{{\rm loc}}
%\newcommand{\Int}{{\rm Int}}
\newcommand{\supp}{{\mathop{\rm supp\ }}}
\newcommand{\id}{{\mathop{\rm \mathbf{id} }}}
\newcommand{\grad}{\nabla}
%\newcommand{\gradw}{\grad_W}
%\newcommand{\dv}{{\ \rm div}}
%\newcommand{\wto}{\rightharpoonup}
\newcommand{\wsto}{\stackrel{*}{\rightharpoonup}}
\newcommand{\wto}{\rightharpoonup}
\newcommand{\la}{\left\langle}
\newcommand{\ra}{\right\rangle}
%\newcommand{\ dx}{ \ dx}
%\newcommand{\ran}{{\rm ran}}
%\newcommand{\A}{\mathcal{A}}
%\newcommand{\B}{\mathcal{B}}
%\newcommand{\C}{\mathcal{C}}
%\newcommand{\CC}{\mathbb{C}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\K}{\mathcal{K}}
%\newcommand{\J}{\mathcal{J}}
\newcommand{\V}{\mathcal{V}}
\def\P{{\mathcal P}}
\def\Pac{\mathcal{P}_{\mathrm{2,ac}}}
\def\epsilon{\varepsilon}
\def\e{\varepsilon}
%\newcommand{\T}{\mathcal{T}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\bxi}{\boldsymbol{\xi}}
\newcommand{\bt}{\mathbf{t}}
%\newcommand{\br}{\mathbf{r}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bnu}{\boldsymbol{		\nu}}
%\newcommand{\bh}{\boldsymbol{h}}
\newcommand{\btau}{\boldsymbol{\tau}}
\newcommand{\bbeta}{\boldsymbol{\eta}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\bkappa}{\boldsymbol{\kappa}}
\newcommand{\bomega}{\boldsymbol{\omega}}
\newcommand{\ird}{\int_{\mathord{\mathbb R}^d}}
\newcommand{\irdrd}{\int_{\mathord{\mathbb R}^d \times \mathord{\mathbb R}^d}}
\newcommand{\E}{\mathcal{E}}
\def\F{\mathcal{F}}
\DeclareMathOperator{\diam}{diam}
\DeclareMathOperator{\dive}{div}
\DeclareMathOperator{\Tan}{Tan}

\setcounter{tocdepth}{1}

\title{A Regularized Particle Method For (Degenerate) Diffusion}

\begin{document}
\maketitle 


\section*{Outline}
\noindent {\color{red} Red} indicates still need to prove. {\color{blue} Blue} indicates would be nice to prove. \\

\begin{enumerate}[1)]
\item Introduction
\item Preliminaries
\begin{itemize}
\item convolution of measures
\item Wasserstein metric
\end{itemize}
\item Regularized internal energies
\begin{itemize}
\item proper $m \geq $/coercive $m >1$
\item inequalities relating regularized entropies to unregularized entropies
\item regularized entropies are lower s cts w.r.t weak-* convergence (\textcolor{red}{$m=1$} and $m>1$)
\item differentiability
\item \textcolor{red}{characterization of subdifferential}
\item convexity when $m\geq2$ {\color{blue} improved convexity along smooth densities (no dependence on $\epsilon$)}
\end{itemize}
\item Gamma convergence of regularized entropies, $m \geq 1$
\begin{itemize}
\item liminf / limsup inequalities for $1\leq m < +\infty$
\item when in the presence of a confinting drift (or interaction) potential...
\begin{itemize}
\item existence of minimizers for all $\e \geq 0$. (still need to do \textcolor{red}{m=1})
\item convergence of minimizers as $\e \to 0$. (still need to do \textcolor{red}{m=1})
\end{itemize}
\end{itemize}
\item Properties of gradient flows, $m \geq 2$
\begin{itemize}
\item \textcolor{red}{By AGS theory and convexity for $m \geq 2$, there exist unique solutions of the gradient flow}
\item \textcolor{red}{By characterization of subdifferential, solutions of continuity equation with $v = \grad \frac{\partial E_\e}{\partial \rho}$ are gradient flows}
\item \textcolor{red}{Corollary: solutions of ODE system are solutions of gradient flows with particle initial data}
\end{itemize}
\item {\color{blue} Gamma convergence of gradient flows (under some strong assumptions)}
\begin{itemize}
\item {\color{red} when $m=2$ we can use convexity of regularized entropy to extend Lions-MasGallic's result to more general initial data, i.e. not just initial data with bounded entropy}
\item {\color{blue} liminf/limsup under some strong assumptions}
\item {\color{blue} compactness?}
\end{itemize}
\item Details of numerical method (details of time discretization, etc.)
\item Numerical results
\begin{itemize}
\item diffusion (m=1) and degenerate diffusion (m=2 and one choice of $m>2$) (though we should emphasize that our method performs best on ``attractive'' problems, otherwise the particle spacing gets too big for epsilon)
\begin{itemize}
\item qualitative properties
\item comparison with exact solutions in dimensions 1 and 2
\item scaling of error in dimensions 1 and 2 for some choice of epsilon and N (okay if epsilon/N scaling is not ``optimal'' and okay 2D error is not W2)
\item does the choice of mollifier matter, or not?
\end{itemize}
\item fokker planck with attractive velocity field and diffusion (m=1)/degenerate diffusion (m=2 and one choice of $m>2$)
\begin{itemize}
\item qualitative properties
\item comparison with exact solutions in dimensions 1 and 2
\item scaling of error in dimensions 1 and 2
\end{itemize}
\item  Keller-Segel 2D (and maybe a little 1D)
\begin{itemize}
\item linear growth/decay of second moment
\item energy decreasing
\item critical mass is correct (does adding a confining potential help us study critical mass in the spreading case?)
\item critical diffusion exponent is correct
\end{itemize}
\end{itemize}
\end{enumerate}

\newpage

 %\tableofcontents
 
\begin{abstract}
We derive a new particle method for linear and nonlinear diffusive gradient flows. This method is essentially based on the regularization of the Wasserstein internal energy through the convolution with a specific class of mollifiers. The resulting regularized energy is finite on the whole space of probability measures, thus including Dirac masses. This energy being of a new form (similar to an interaction energy, up to the composition with a nondecreasing function), we characterize its subdifferential and we prove basic properties such as lower semicontinuity, differentiability and convexity. This enables us to prove that the regularized gradient flow is well-posed when the diffusion is at least quadratic, and that the regularized energy $\Gamma$-converges to the original internal energy. When the diffusion is at least quadratic and under reasonable regularity assumptions on the regularized gradient flow, we show that it converges to the original diffusion equation using Serfaty's result on the convergence of gradient flows in metric spaces. The final numerical scheme is then obtained by solving an ODE system whose solutions are shown to be solutions to the regularized gradient flow with Dirac masses as initial data. We provide error plots and numerical simulations illustrating the behaviour of this particle method in test cases such as the heat and porous medium equations, and we recover critical properties of the Keller--Segel equation in one and two space dimensions by adding an interaction term to the energy.
\end{abstract}


\section{Introduction}
We introduce a new particle method for gradient flows involving linear and nonlinear diffusion. This method is based on a specific regularization of the internal energy via a smooth mollifier, enabling us to define a regularized internal energy which is well-defined on Borel probability measures which are not necessarily absolutely continuous with respect to the Lebesgue measure, and in fact on all Borel probability measures. This approach gives rise to a regularized gradient flow, that is, the gradient flow for the regularized internal energy, which, when restricted to convex combinations of Dirac measures, defines a discretized-regularized gradient flow on Euclidean space.

The diffusion equations in which we are interested are the continuity equations of the form
\be\label{eq:diffusion-general}
	\partial_t\mu = \dive (\mu \grad (U'\circ\mu)) \quad \mbox{on $[0,T]\times\R^d$},
\ee
for some finite final time $T>0$, where $\mu\colon [0,T] \to \P(\R^d)$ is an unknown curve of Borel probability measures, and $U'$ is the derivative of the density of internal energy $U \colon [0,\infty) \to \R$. By taking $U(s) = s\log s$ or $U(s) = s^m/(m-1), m>1$ we recover the classical heat equation
\bes
	\partial_t\mu = \Delta \mu \quad \mbox{on $[0,T]\times\R^d$},
\ees
or the porous medium equation
\bes
	\partial_t\mu = \Delta (\mu^m) \quad \mbox{on $[0,T]\times\R^d$},
\ees
respectively.

Let us only focus on solutions to \eqref{eq:diffusion-general} belonging to $\P_2(\R^d)$, the elements of $\P(\R^d)$ with bounded second moment. Our regularization relies on the gradient flow structure of \eqref{eq:diffusion-general} with respect to the quadratic Wasserstein distance for some energy functional. Given two probability measure $\mu,\nu\in \P_2(\R^d)$ we define the quadratic Wasserstein distance $W_2(\mu,\nu)$ between $\mu,\nu$ by
\be \label{eq:2-wasserstein}
	W_2(\mu,\nu) = \inf_{\gamma \in \Gamma(\mu,\nu)} \left( \int_{\R^d \times \R^d} |x-y|^2 \,d\gamma(x,y)\right)^{1/2},
\ee
where $\Gamma(\mu,\nu)$ is the space of probability measures (also called transport plans) on $\R^d\times\R^d$ with first marginal $\mu$ and second marginal $\nu$. Note that $W_2(\mu,\nu)$ is since $\mu,\nu$ have bounded second moments, and therefore the couple $(\P_2(\R^d),W_2)$ defines a metric space; furthermore this space is separable and complete (see \cite[Proposition 7.1.5]{AmGiSa} for example). In this setting the natural internal energy functional $\F \colon \P_2(\R^d) \to (-\infty,\infty]$---we justify why $\F>-\infty$ later---is
\be \label{eq:internal-energy}
	\F(\mu) = \begin{cases}
		\displaystyle \int_{\R^d} U(\mu(x)) \,d x & \mbox{for all $\mu \in \Pac(\R^d)$},\\
		+\infty & \mbox{otherwise},
	\end{cases}
\ee
where $\Pac(\R^d)$ is the subset of $\P_2(\R^d)$ of probability measures which are absolutely continuous with respect to the Lebesgue measure. Note that we denote by the same symbol a probability measure and its density with respect to the Lebesgue measure, whenever the latter exists. It can be shown that the space $(\P_2(\R^d),W_2)$ enjoys a ``weak Riemannian'' structure which allows us to define a notion of gradient of $\F$. Indeed, formally one defines the quadratic Wasserstein gradient on $W_2(\R^d)$ by
\bes
	\grad_{W_2} \F(\mu) = -\dive \left(\mu \grad \frac{\delta \F}{\delta \mu}\right) \quad \mbox{for all $\rho \in \P_{2}(\R^d)$},
\ees
where $\delta \F/\delta \mu = U'\circ\mu$ is the first variation density of $\F$ at $\mu$, whenever the right-hand side makes sense. Then one can write \eqref{eq:diffusion-general} under the gradient flow, or steepest descent, form
\bes
	\rho'(t) = - \grad_{W_2} \F(\mu(t)),
\ees
where the time and space derivatives have to be interpreted in the distribution sense; see \cite[Equation (8.3.8)]{AmGiSa}. Formally, this shows that indeed the diffusion equation \eqref{eq:diffusion-general} can be seen as the gradient flow equation in the quadratic Wasserstein space with respect to the functional $\F$. For a rigorous theory of gradient flows for diffusion equations we refer the reader to \cite{JoKiOt,Villani,Villani2,AmGiSa,AmGi,AmSa,Santambrogio}.

When the density of internal energy $U$ can be written as $U(s)=sF(s)$ for all $s\in(0,\infty)$ for some other function $F\colon (0,\infty) \to \R$, then the internal energy in \eqref{eq:internal-energy} can be rewritten as
\bes
	\F(\mu) = \begin{cases}
		\displaystyle \int_{\R^d} F(\mu(x)) \,d\mu(x) & \mbox{for all $\mu \in \Pac(\R^d)$},\\
		+\infty & \mbox{otherwise}.
	\end{cases}
\ees
The internal energy for the heat and porous medium equations are therefore obtained for $F(s) = log s$ and $F(s) = s^{m-1}/(m-1)$, respectively. Now, for any $\e>0$ and a smooth mollifier $\varphi_\e \colon \R^d \to [0,\infty)$ whose regularity assumptions we discuss later, we can define the regularized energy $\F_\e \colon \P_2(\R^d) \to \R$ as
\bes
	\F_\e(\mu) = \int_{\R^d} F(\varphi_\e*\mu(x)) \,d\mu(x) \quad \mbox{for all $\mu\in \P_2(\R^d)$},
\ees
where $*$ stands for the convolution operator, and $F\colon (0,\infty) \to \R$ is simply given by $F(s) = U(s)/s$ for all $s\in(0,\infty)$. By the assumptions we clarify later on $\varphi_\e$ and $F$, the energy $\F_\e$ is well-defined and finite on $\P_2(\R^d)$, and in fact on all of $\P(\R^d)$. This energy induces a regularized gradient flow with associated continuity equation
\bes	
	\partial_t \mu + \dive \left( \mu v_\e \right) = 0,
\ees
where
\bes
	v_\e = - \grad \left(F\circ (\varphi_\e * \mu)\right) - \grad\varphi_\e * \left(\mu F'\circ(\varphi_\e*\mu)\right).
\ees

\comment{Give the discretized-regularized gradient flow here, as well as the particle method.}

\comment{Give here main results of the paper.}

\comment{Give here structure of the paper.}

\begin{itemize}
\item A regularized particle method for diffusion and degenerate diffusion
\item Previous work
\item Definition of regularized energies and overview of numerical method
\item Benefits of our approach
\item Future work
\begin{itemize}
\item Gamma convergence of gradient flows (without assumptions)
\item Quantitative estimates on convergence (especially optimal scaling of epsilon vs N)
\item Can vortex spreading ideas be used to get  long-time results for diffusive problems?
\end{itemize}
\end{itemize}

\section{Preliminaries}
\subsection{Notation}
As already used in the introduction, $\P(\Rd)$ denotes the set of Borel probability measures on $\Rd$, $\P_2(\Rd)$ denotes the elements of $\P(\Rd)$ with finite second moment, and $\Pac(\Rd)$ denotes the elements of $\P_2(\Rd)$ which are absolutely continuous with respect to the Lebesgue measure. Also, for any $R>0$, we define $\P_R(\R^d)$ to be the set of Borel probability measures compactly supported in $B_R(0)$, the open ball of radius $R$ centered at the origin.

We write $\mathcal{L}^d$ the $d$-dimensional Lebesgue measure, and for a given $\mu\in\P(\Rd)$ we write $\mu \ll \mathcal{L}^d$ if $\mu$ is absolutely continuous with respect to the Lebesgue measure.

For a given sequence $(\mu_n)_n \subset \P(\Rd)$ and some $\mu\in\P(\Rd)$, we write $\mu_n \wsto \mu$ if $(\mu_n)_n$ converges to $\mu$ in the weak-* topology of probability measures, i.e., in the duality with bounded continuous functions. 

Given a metric space $X$ and a functional $G\colon X \to (-\infty,\infty]$, we write $D(G) = \{ x\in X \mid G(x) < +\infty\}$, and we say that $G$ is proper if $D(G) \neq \emptyset$.

%, and let $\P_2(\Rd)$ denote the set of probability measures with finite second moment, $\int |x|^2 d \mu(x) < +\infty$.
%\begin{defi}
%Let $p\in\N_0$ and $\mu \in\P(\Rd)$. We define the $p$-th moment of $\mu$ by
%\bes
%	M_p(\mu) = \ird |x|^p \,d\mu(x).
%\ees
%If $M_p(\mu) < \infty$, we say that $\mu$ has bounded, or finite, $p$-th moment and write $\mu \in \P_p(\R^d)$.
%\end{defi}

Throughout the present work, we consider convolutions of probability measures with integrable functions. We now recall this notion of convolution.
\begin{defi} \label{def:conv}
Let $\mu \in\P(\Rd)$ and $\phi\colon \R^d \to [-\infty,\infty]$ be a measurable function. We define $\phi*\mu\colon \R^d \to[-\infty,\infty]$ as
\be\label{eq:conv-meas}
	\phi*\mu(x) = \int_{\Rd} \phi(x-y) \,d\mu(y) \quad \mbox{for all $x\in\Rd$},
\ee
whenever the right-hand side makes sense.
\end{defi}

\begin{remark} \label{rem:properties}
	For $\mu \in \P(\Rd)$ and $\phi \in L^1(\Rd)$, $\phi*\mu \ll \mathcal{L}^d$, and we slightly abuse notation to identify the measure $\phi*\mu$ with its density with respect to Lebesgue measure  $\phi*\mu \in L^1(\Rd)$. %If in addition $\phi \in C_b(\Rd)$, then we also have $\mu *\phi \in C_b(\Rd)$. Also,  if $\phi \in \P_1(\Rd)\cap\P_2(\Rd)$, then $\mu*\phi \in \P_2(\Rd)$.
\end{remark}

We give now useful property of the convolution operator which we use throughout this paper.
\begin{lem} \label{convolutionlemma}
	Let $\mu\in\P(\R^d)$, and let $\psi\in L^1(\R^d)$ be even and $\phi\colon\R^d \to (-\infty,\infty]$ be measurable and bounded from below. Then
\bes
	\ird \phi \,d(\psi*\mu) = \ird \phi*\psi \,d\mu.
\ees
\end{lem}
\begin{proof}
	Compute, using \eqref{eq:conv-meas}, the evenness of $\psi$ and Fubini's theorem,
\begin{align*}
	\ird \phi(x) \,d(\psi*\mu)(x) &= \ird \ird \phi(x) \psi(x-y) \,d\mu(y) \,dx = \ird \ird \phi(x) \psi(y-x) \,dx \,d\mu(y)\\
	&= \ird \psi*\phi(y) \,d\mu(y). \qedhere
\end{align*}
\end{proof}

\subsection{Mollifiers}
In what follows, we consider a mollifier $\varphi$ that satisfies the following assumption.
\begin{hyp} \label{mollifierAssumption}
$\varphi\colon\Rd \to [0,\infty)$ satisfies $\varphi = \zeta * \zeta$ for a Schwartz class function $\zeta: \Rd \to [0,\infty)$, with $\zeta(-x) = \zeta(x)$ for all $x\in\Rd$ and $\int \zeta = 1$.  \end{hyp}
Note that this hypothesis is verified by typical Gaussian mollifiers, and any $\varphi$ satisfying the above hypothesis has finite first moment. For any $\epsilon >0$, we write $\varphi_\e =  \e^{-d} \varphi (\cdot/\e)$ and $\zeta_\e = \e^{-d} \zeta(\cdot/\e)$.

\begin{remark}
	In Hypothesis \ref{mollifierAssumption} we impose similar assumptions on the mollifier $\varphi$ as Lions and Mas-Gallic in their study of a regularized particle method for degenerate diffusion with $m=2$ \cite{LionsMasGallic}. Note that they do not require $\zeta$ to be even and instead write $\varphi = \hat{\zeta}*\zeta$, where $\hat{\zeta}(x) = \zeta(-x)$ for all $x\in\R^d$. While our results continue to hold under their weaker hypothesis on the mollifier, we prefer to assume that $\zeta$ is even in order to simplify notation.
\end{remark}

%The following proposition summarises a few properties of the mollifier. Its proof is left to the reader as it is a straightforward consequence of Remark \ref{rem:properties} and the assumptions on $\varphi$.
%\begin{prop} \label{prop:properties}
%	For any $\mu \in \P_2(\Rd)$ the following properties hold.
%\begin{itemize}
%	\item $\mu * \varphi_\e \in C_b(\Rd)$, with $0\leq\mu *\varphi_\e\leq \|\varphi_\e\|_\infty$,
%	\item $\mu* \varphi_\e \in \P_2(\Rd)$.
%\end{itemize}
%\end{prop}

We conclude this section with two propositions on the regularization of measures by convolution with a mollifier. The first shows that if a sequence of measures converges in the weak-* topology of $\P(\Rd)$, then the mollified sequence converges to the same limit. The second is found in \cite{LionsMasGallic}, whose proof we include for the reader's convenience.

\begin{prop} \label{narrow convergence mollified sequence}
	Let $(\mu_\e)_\e$ be a sequence in $\P(\R^d)$ such that $\mu_\e \wsto \mu$ as $\e\to0$ for some $\mu\in\P(\R^d)$. Then $\varphi_\e *\mu_\e \wsto \mu$.
\end{prop}

\begin{proof}
	By \cite[Remark 5.1.6]{AGS}, it suffices to show that $\varphi_\e *\mu_\e$ converges to $\mu$ in distribution, that is, in the duality with smooth, compactly supported functions. For all $f \in C^\infty_c(\Rd)$,
\begin{align*}
	\left| \ird f \,d (\varphi_\e *\mu_\e) - \ird f \,d\mu \right| &\leq \left| \ird f \,d (\varphi_\e *\mu_\e) - \ird f \,d\mu_\e \right| + \left| \ird f \,d\mu_\e - \ird f \,d\mu \right|
\end{align*}
Since $\mu_\e \wsto \mu$, the second term goes to zero. We bound the first term as follows:
\begin{align*}
& \left| \ird f \,d (\varphi_\e *\mu_\e) - \ird f \,d\mu_\e \right| = \left| \ird\ird (f(y) - f(x)) \varphi_\e(x-y)\,dy \,d \mu_\e(x) \right| \\
 &\quad \leq \|\grad f\|_\infty \ird\ird |x-y| \varphi_\e(x-y) \,dy \,d\mu_e(x) = \|\grad f\|_\infty \ird\ird \left| \frac{z}{\e^d} \right| \varphi \left(\frac{z}{\e} \right) \,dz \,d\mu_\e(x) \\
 &\quad = \e \|\grad f\|_\infty \ird |z | \varphi(z) \,dz ,
\end{align*}
which goes to zero as $\e \to 0$.
\end{proof}

\begin{prop} \label{move mollifier prop}
Let $f\colon \R^d \to \R$ be a Lipschitz function with constant $L_f$, let $h\in L^1(\R^d)$ and let $\nu$ be a finite, signed Borel measure on $\R^d$. Suppose moreover that there exist $p\in(0,\infty)$ and $C_\zeta>0$ such that $|\zeta(x)| \leq C_\zeta|x|^{-p}$ and $p>d$. Then there exists a constant $C >0$ only depending on $f,\zeta,h$ and $\nu$ (and not on $\e$) so that
\[ 
	\left| \ird \zeta_\e *(f\nu)h - \ird (\zeta_\e *\nu)fh \right|  \leq   \e^{1-q} L_f \norm{(\zeta_\e*|\nu|)h}_{L^1(\R^d)} + \e^{1-q} C \quad \text{ for all } \e >0.
\]
\end{prop}

\begin{proof}
	Let $q = d/p < 1$ and compute
\begin{align*}
	\left| \ird \zeta_\e *(f\nu)h - \ird (\zeta_\e *\nu)fh \right| &\leq \ird \ird \zeta_\e(x-y) |h(x)| |f(x)-f(y)| \,d|\nu|(y) \,dx\\
	&\leq L_f  \ird \ird \zeta_\e(x-y) |h(x)| |x-y| \,d|\nu|(y) \,dx\\
	&= L_f  \ird \int_{B_{\e^{1-q}}(x)} \zeta_\e(x-y) |h(x)| |x-y| \,d|\nu|(y) \,dx\\
	&\phantom{{}={}}+ L_f  \ird \int_{\R^d \setminus B_{\e^{1-q}}(x)} \zeta_\e(x-y) |h(x)| |x-y| \,d|\nu|(y) \,dx\\
	&\leq \e^{1-q} L_f \ird \zeta_\e*|\nu|(x) |h(x)| \,dx\\
	&\phantom{{}={}}+ \e^{p-d} L_f C_\zeta \ird \int_{\R^d \setminus B_{\e^{1-q}}(x)} |h(x)| |x-y|^{1-p} \,d|\nu|(y) \,dx\\ 
	&\leq \e^{1-q} L_f \ird \zeta_\e*|\nu|(x) |h(x)| \,dx\\
	&\phantom{{}={}}+ \e^{p-d + (1-q)(1-p)} L_f C_\zeta \norm{h}_{L^1(\R^d)} |\nu|(\R^d)\\
	&= \e^{1-q} L_f \left( \norm{(\zeta_\e*|\nu|)h}_{L^1(\R^d)} + C_\zeta \norm{h}_{L^1(\R^d)} |\nu|(\R^d) \right),
\end{align*}
which is the desired result by setting $C:= L_f C_\zeta \norm{h}_{L^1(\R^d)} |\nu|(\R^d)$.
\end{proof}


\subsection{Other preliminary results}

We recall a general result due to Ambrosio, Gigli, and Savar\'e on weak convergence of maps $v_n \in L^p(d\mu_n)$ for measures $\mu_n$ converging narrowly to some $\mu$. This result plays a key role in our proof of the $\Gamma$-convergence of the energies and gradient flows.

\begin{defi}[weak convergence with varying measures {(c.f. \cite[Definition 5.4.3]{AGS})}] \label{weakvaryingdef}
Given a sequence $(\mu_n)_n \subset \P(\Rd)$ converging in the weak-* topology to $\mu \in \P(\Rd)$, we say that $(v_n)_n \subset L^1(d \mu_n)$ \emph{converges weakly} to $v \in L^1(d \mu)$ if 
\bes
	\lim_{n\to\infty} \ird f(x) v_n(x) \,d\mu_n(x) = \ird f(x) v(x) \,d\mu(x).
\ees
Furthermore, we say that $(v_n)_n$ converges \emph{strongly} to $v$ if 
\bes
	\limsup_{n\to\infty} \norm{v}_{L^1(d\mu_n)} \leq \norm{v}_{L^1(d\mu)}.
\ees
\end{defi}

\begin{prop}[properties of convergence with varying measures {(c.f. \cite[Theorem 5.4.4]{AGS}}] \label{AGSthm}
For $p>1$, suppose $\mu_n \wsto \mu$ and  $\sup_{n \in \mathbb{N}} \| v_n\|_{L^p(d \mu_n)} <+\infty$.
\begin{enumerate}[(i)]
\item There exists a subsequence of $v_n$ converging weakly to $w \in L^1(\mu)$. \label{weakcpt}
\item If $v_n$ weakly converges to $v \in L^1(d \mu)$, then $\liminf_{n \to +\infty} \|v_n\|_{L^2(d \mu_n)} \geq \|v\|_{L^2(d \mu)}$. \label{weaklsc}
\item If $v_n$ strongly converges to $v \in L^p(d \mu)$ and $\sup_{n \in \mathbb{N}} \int |x|^p d \mu_n <+\infty$, then for all $f \in C^\infty_c(\Rd)$,
\[ \lim_{n \to +\infty} \int f |v_n|^p d \mu_n = \int f |v|^p d \mu . \] \label{strongcty}
\end{enumerate}
\end{prop}
\subsection{Wasserstein metric}

As alrrady used in the introduction of this paper, given $\mu,\nu\in\P(\R^d)$ we write $\Gamma(\mu,\nu) := \{\gamma \in\P(\R^d\times\R^d) \mid {\pi^1}_\# \gamma = \mu,\, {\pi^2}_\# \gamma = \nu\}$, where $\pi^1,\pi^2\colon \R^d \times \R^d \to \R^d$ are the projections of $\R^d\times \R^d$ onto the first and second copy of $\R^d$, respectively. In optimal transport theory one calls an optimal transport plan between two probability measures $\mu$ and $\nu$ any $\gamma_\mathrm{o} \in \Gamma(\mu,\nu)$ solving Kantorovich's optimal transport problem for the quadratic cost, i.e, 
\bes
	 \mbox{minimise  $\displaystyle \int_{\R^d\times \R^d} |x-y|^2 \,d\gamma(x,y)$ over $\gamma\in \Gamma(\mu,\nu)$}.
\ees
Any such $\gamma_\mathrm{o}$ is said to be optimal, in which case we write $\gamma_\mathrm{o} \in \Gamma_\mathrm{o}(\mu,\nu)$. For any $\mu,\nu\in\P(\R^d)$, Kantorovich's problem admits a solution---this shows that the Wasserstein distance as defined in \eqref{eq:2-wasserstein} makes sense. If moreover $\mu,\nu\in\P_2(\R^d)$, and either $\mu$ or $\nu$ is absolutely continuous, then it admits a unique solution $\gamma_\mathrm{o}$, and
\bes
	\gamma_\mathrm{o} = (\text{id},T_\mathrm{o})_\#\mu,
\ees
where $T_\mathrm{o}$ is the unique (up to $\mu$-negligible sets) solution of Monge's problem, and $T_\mathrm{o} = \grad \varphi_\mathrm{o}$ for some convex function $\varphi_\mathrm{o}$. 

%\begin{itemize}
%\item Define W2, optimal transport maps, optimal transport plans (note that the optimal transport map is characterized by being the gradient of a convex function) (use $\bgamma \in \Gamma(\mu,\nu)$ to denote transport plans)
%\end{itemize}
%The Wasserstein metric on the space of probability measures with finite second moment has a formal Riemannien structure, with a notion of tangent bundle to $\P_2(\Rd)$.
%\begin{defi}[tangent bundle] \label{tandef}
%Given $\mu \in \P_2(\Rd)$, $\rm{Tan}_\mu \P_2(\Rd) := \overline{\{ \grad \psi : \psi \in C^\infty_c(\Rd) \}}^{L^2(\mu)}$.
%\end{defi}

We give now a couple definitions on curves in metric spaces useful to the proof of convergence of gradient flows given in the present paper. For the sake of generality we state these definitions in a complete, separable metric space $(X,d)$.

\begin{defi}[absolutely continuous curve]\label{defi:ac-curve}
	Let $p\in\N$, and let $v\colon (0,\infty) \to X$. Then $v$ is said to be \emph{$p$-absolutely continuous} if there exists $f\in L^p_\loc((0,\infty))$ such that 
\be\label{eq:ac-p}
	d(v(t),v(s)) \leq \int_s^t f(r)\,d r \quad \mbox{for all $t,s\in (0,\infty)$ with $s\leq t$.}
\ee
We write in this case $v\in AC^p_\loc((0,\infty);X)$. We write $AC_\loc((0,\infty);)$ for $AC^1_\loc((0,\infty);X)$ and $v$ is simply said to be absolutely continuous if it is $1$-absolutely continuous.
\end{defi}

\begin{defi}[metric derivative]\label{defi:metric-derivative}
Let $v\colon (0,\infty) \to X$. Then the limit
\bes
	|v'|_d(t) := \lim_{s\to t} \frac{d(v(t),v(s))}{|t-s|}
\ees
is called the \emph{metric derivative} of $v$ at $t\in (0,\infty)$ whenever it exists.
\end{defi}

In fact, we have that $|v'|_{d}$ exists almost everywhere and belongs to $L^p_\loc((0,\infty))$ if and only if $v\in AC^p_\loc((0,\infty);X)$. In this case $|v'|_d$ satisfies \eqref{eq:ac-p} in place of $f$ and
\bes
	|v'|_d(t) \leq f(t) \quad \mbox{for almost every $t\in (0,\infty)$ and all $f$ satisfying \eqref{eq:ac-p}.}
\ees

In Euclidean space $\R^d$ the constant-speed geodesic between two points $x_1,x_2 \in \R^d$ is given by the convex combination $x_\alpha = (1-\alpha) x_0 + \alpha x_1$ for all $\alpha\in[0,1]$. In the quadratic Wasserstein space, given $\mu_0,\mu_1 \in \P_2(\R^d)$, the constant-speed geodesic connecting $\mu_0$ to $\mu_1$ is given by
\bes
	\mu_\alpha = ((1-\alpha) \pi^1 + \alpha \pi^2)_\# \gamma_\mathrm{o} \quad \mbox{for all $\alpha\in[0,1]$},
\ees
with $\gamma_\mathrm{o}\in \Gamma_\mathrm{o}(\mu,\nu)$. If $\gamma_\mathrm{o}$ is induced by a map $T_\mathrm{o}$, then
\bes
	\mu_\alpha = ((1-\alpha)\text{id} + \alpha T_\mathrm{o})_\# \mu_0.
\ees
\begin{defi}[semiconvexity along geodesics]\label{defi:semiconvexity-geod}
We say that $\E\colon (\P_2(\R^d),W_2) \to [-\infty,\infty]$ is \emph{semiconvex along geodesics} if there is $\lambda \in \R$ such that $\E$ is \emph{$\lambda$-convex} along geodesics, i.e., for all $\mu_0,\mu_1\in \P_2(\R^d)$,
\bes
	\E(\mu_\alpha) \leq (1-\alpha)\E(\mu_0) + \alpha\E(\mu_1) - \frac{\lambda (1-\alpha)\alpha}{2} W_2^2(\mu_0,\mu_1) \quad \mbox{for all $\alpha\in[0,1]$},
\ees
When $\lambda=0$ we simply say that $\E$ is \emph{convex along geodesics}.
\end{defi}

%\begin{itemize}
%\item Define (locally) absolutely continuous curves, metric derivative $|\mu'|(t)$ and $AC^2_\loc((0, +\infty);\P_2(\Rd))$ wrt $W_2$
%\item Define geodesics, generalized geodesics, and $\lambda$-convexity
%\item Define proper, coercive, lower semicontinuous
%\end{itemize}

For any such energy, we may define its subdifferential (c.f. \cite[Equation 10.3.12]{AGS}). (Since this \emph{reduced} subdifferential is sufficient for our purposes and we do not require the more general \emph{extended} subdifferential \cite[Definition 10.3.1]{AGS}, we follow \cite{5person} and simply refer to it as the \emph{subdifferential}.)
\begin{defi}[subdifferential] \label{subdiffdef}
Given $\E:\P_2(\Rd) \to \R \cup \{+\infty\}$ proper  and lower semicontinuous, $\mu \in \P_2(\Rd)$, and $\bxi:\Rd \to \Rd$ with $\bxi \in L^2(d\mu)$, then $\bxi$ belongs to the \emph{subdifferential} of $\E$ at $\mu$, written $\bxi \in \partial \E(\mu)$, if as $\nu \xrightarrow{W_2} \mu$,
\[ \E(\nu) - \E(\mu) \geq \inf_{\bgamma \in \Gamma_0(\mu,\nu)} \int_{\Rd \times \Rd} \la \bxi(x),y-x \ra d\bgamma(x,y) + o(W_2(\mu,\nu)) . \]
%Furthermore, if 
%\[ \bxi \in \partial \E(\mu) \text{ and } \|\bxi\|_{L^2(d\mu)} \leq \|\bbeta\|_{L^2(\mu)} \ \forall \bbeta \in \partial E(\mu) ,\]
%we write $\bxi \in \partial^\circ \E(\mu)$.
\end{defi}


We now recall the definition of gradient flow (c.f. \cite[Proposition 8.3.1, Definition 11.1.1]{AGS}). Before this let us give the definition of tangent space in $\P_2(\R^d)$.
\begin{defi}
	Let $\mu \in \P_2(\R^d)$. The \emph{tangent space} at $\mu$ is defined as
\bes
	\Tan_\mu \P_2(\R^d) = \overline{\left\{ \grad\phi \mid \phi \in C_\mathrm{c}^\infty(\R^d) \right\}},
\ees
where the closure is taken in $L^2_\mu(\R^d)$.
\end{defi}

\begin{defi}[gradient flow] \label{gradientflowdef}
	Suppose $\E\colon \P_2(\Rd) \to \R \cup \{+\infty\}$ is proper and lower semicontinuous. A curve $\mu \in AC^2_\loc((0,+\infty); \P_2(\Rd))$ is a \emph{gradient flow of $\E$} if there exists a vector field $v\colon (0,\infty)\times \R^d \to [-\infty,\infty]^d$ such that $v(t,\cdot)\in\Tan_{\mu(t)}\P_2(\R^d)$, $t\mapsto \|v(t,\cdot)\|_{L^2_{\mu(t)}(\R^d)} \in L^2_\loc((0,\infty))$ and $- v(t) \in \partial \E(\mu(t))$ for almost every $t\in(0,\infty)$, and such that 
\[ 
	\frac{d}{dt} \mu(x,t) + \grad \cdot (v(x,t) \mu(x,t)) = 0 
\]
holds in the sense of distributions on $(0,\infty)\times\R^d$.
\end{defi}

\section{Regularized internal energies}
We consider internal energies and their regularization by convolution with a mollifier $\varphi_\e(x)$.
\begin{defi}[regularized internal energies] \label{energy def}
\begin{align}
 \label{eq:energy}
	\F(\mu) = \begin{cases} \int F(\mu) \,d\mu & \mbox{if $\mu \ll \mathcal{L}^d$,} \\ +\infty & \mbox{otherwise,} \end{cases} \quad  \F_\e(\mu) =  \int F(\varphi_\e * \mu) \, d\mu ,
\end{align}
We will often consider the energies in (\ref{eq:energy}) jointly, referring to them as $\F_\e$ for $\e \geq 0$.	
{\color{Aquamarine} State hypotheses on $F$. For simplicity, I have done everything for $F(s) = \log(s)$ and $F(s) = \frac{1}{m-1} s^{m-1}$ for $m > 1$. I think most of these results hold for general internal energies. Feel free to adapt the proofs to that level of generality if you think that would be better. We still need to state what conditions ensure that the regularized entropy is well defined for $m=1$. I think finite second moment is enough.}
\end{defi}

\begin{remark}[proper]
Note that for all $\mu \in \P(\Rd)$, $F_\e(\mu) <+\infty$. This is a consequence of the fact that $F(s)$ is increasing and $\|\varphi_\e*\mu\|_\infty \leq \|\varphi_\e\|_\infty$, so $\F_\e(\mu) = \int F(\varphi_\e*\mu) d\mu \leq F(\|\varphi_\e\|_\infty) < +\infty$.
\end{remark}

\begin{remark}[coercive]
{\color{Aquamarine} Explain why/under what conditions $\F_\e$ is coercive. This is immediate for $m > 1$, sinc it is bounded below. For $m=1$, it should still be true for $\mu$ with finite second moment. }
\end{remark}

In the following results, we will often distinguish between two cases: $1 \leq m \leq 2$ and $m >2$. In the former, $F(s)$ is concave, and since a concave function lies below its tangent line, we have for all $x,y >0$,
\begin{align} \label{tangent line concave} 
\begin{cases} \log(y) - \log(x) \geq (y-x) y^{-1} &\text{ for } m=1 , \qquad \qquad \qquad \\
y^{m-1} - x^{m-1}  \ \ \geq (m-1)(y-x) y^{m-2} &\text{ for }1 \leq m \leq 2. \end{cases}
\end{align}
Likewise, when $m>2$, $F(s)$ is convex, and since a convex function lies above its tangent line, for all $x,y >0$,
\begin{align} \label{tangent line convex} 
y^{m-1} - x^{m-1} \geq (m-1)(y-x) x^{m-2} &\text{ for }m\geq2. 
\end{align}

{\color{Aquamarine}  \begin{remark}
Emphasize that our regularized energies have a novel structure -- sort of a blend of interaction and internal energies -- fall outside the scope of existing theory. See later section for existence/uniqueness of gradient flows of these energies.
\end{remark}}

{\color{Aquamarine}  \begin{remark}
Explain why we leave a $\mu$ hanging out of the convolution, as it would be more similar to previous work, including Craig/Topalogu, if we mollified ``all of'' $\mu$. (It's so we don't have to compute a convolution at every step of the numerical method.)
\end{remark}}

We have the following inequalities relating the energy and its regularization.

\begin{prop} \label{relative sizes lemma}
Consider $\F_\e$ as in Definition \ref{energy def}, for $\e \geq 0$. For $1 \leq m \leq 2$, we have
\begin{align} \label{relative sizes equation}
\F^m(\mu) + C_\e \geq \F^m_\e(\mu) \geq \F^m(\zeta_\e*\mu) 
\end{align}
where $C_\e= C_\e(m,\mu)  \to 0$ as $\e \to 0$. For $m \leq 2$, we have
\begin{align} \label{relative sizes equation 2}
 \F^m_\e(\mu) \leq \F^m(\zeta_\e*\mu) .
 \end{align}
 Furthermore, we have the following lower bounds on the regularized energies:
 \begin{align} \label{lower bounds}  \F^m_\e(\mu)  \geq  \begin{cases} (2\pi/\delta)^{d/2} - \delta M_2(\zeta_\e*\mu) &\text{ if } m =1, \\ 0 &\text{ if } m>1 ,\end{cases} 
 \end{align}
 where the first bound holds for all $\delta >0$ and $M_2(\zeta_\e*\mu) = \int |x|^2 d\zeta_\e *\mu$ is the second moment of the regularized measure.
\end{prop}

\begin{proof}
We begin with (\ref{relative sizes equation}). To prove the first inequality, we may assume without loss of generality that $\mu \in D(\F)$.
First, we show the result for the entropy ($m=1$). Note that
\begin{align} \label{relative entropy relation} \F^1(\mu)-\F^1_\e(\mu) =  \mathcal{H}(\mu | \varphi_\e *\mu) ,\end{align} where $\mathcal{H}$ is the relative entropy,
\begin{align*}
 \mathcal{H}(\mu | \gamma) : = \begin{cases} \int \log \left( \frac{d \mu}{d \gamma} \right) d \mu &\text{if } \mu \ll \gamma, \\ + \infty &\text{otherwise.}\end{cases}
\end{align*}
By Jensen's inequality for the convex function $x \log x$,  the relative entropy
is nonnegative, which gives the result.

Now, we show the first inequality for $m>1$. Combining inequality (\ref{tangent line  concave}) with H\"older's inequality,
\begin{align*}
\F^m(\mu) - \F^m_\e(\mu) &= \frac{1}{m-1} \int \left( \mu^{m-1} - (\varphi_\e*\mu)^{m-1} \right) d \mu \geq \int \left(\mu - \varphi_\e*\mu \right) \mu^{m-2} d \mu 
\\ 
&\geq - \|\mu - \varphi_\e* \mu\|_{L^m(\Rd)} \|\mu^{m-1}\|_{L^{m/(m-1)}(\Rd)} = - \|\mu - \varphi_\e* \mu\|_{L^m(\Rd)} \|\mu\|_{L^m(\Rd)}^{m-1} .
\end{align*}
Since $\mu \in D(\F^m)$ implies $\mu \in L^m(\Rd)$, the first term goes to zero as $\e \to 0$ and the second term remains bounded. This gives the result.


We now turn to the second inequality. By the fact that $\varphi_\e = \zeta_\e * \zeta_\e$ and Jensen's inequality for the concave function $F(s)$,
\begin{align} \label{rel size ineq1}
 F(\varphi_\e * \mu_\e) &= 
 F \left( \int \zeta_\e(y) \zeta_\e*\mu_\e(\cdot-y) dy \right)  \geq   \int \zeta_\e(y) F \left(\zeta_\e*\mu_\e(\cdot-y) \right) dy   =   \zeta_\e* F \left(\zeta_\e*\mu_\e \right).
\end{align}
Consequently,
\begin{align} \label{rel size ineq2}
\F_\e(\mu_\e) &= \int F(\varphi_\e * \mu_\e) d \mu_\e \geq   \int \zeta_\e*  F \left(\zeta_\e*\mu_\e \right)  d \mu_\e  = \int   F \left(\zeta_\e*\mu_\e \right)  d (\zeta_\e*\mu_\e) = E \left( \zeta_\e*\mu_\e  \right) .
\end{align}

Now, we show (\ref{relative sizes equation 2}). Since $F(s)$ is convex, this is simply a consequence of reversing the inequalities in (\ref{rel size ineq1}) and (\ref{rel size ineq2}).

The lower bound (\ref{lower bounds}) are a consequence of \cite[Lemma 4.1]{CPSW} when $m =1$ and the fact that $F(s) = \frac{1}{m-1}s^{m-1} \geq 0$ when $m >1$.
\end{proof}



\begin{prop}[lower semicontinuity] \label{lower semicontinuity}
For all $\e >0$, $\F^m_\e$ is lower semicontinuous with respect to weak-* convergence in $\P(\Rd)$.
\end{prop}
\begin{proof}
Suppose $\mu_n \wsto \mu$. We must show $\liminf_{n \to +\infty} \F^m_\e(\mu_n) \geq \F^m_\e(\mu)$. Without loss of generality, we replace $\mu_n$ by a subsequence which attains the limit on the left hand side, and we may assume that this limit is finite. Consequently, there exists $C>0$ so that 
\begin{align} \label{lower semicty ineq 0} 
\F^m_\e(\mu_n) < C \quad \text{ for all } n \in \mathbb{N} .
\end{align}

We now consider the case when $1 < m \leq 2$. For any $a,b >0$, $|a^{m-1} -b^{m-1}| \leq |a-b|^{m-1}$. Combining this with Jensen's inequality for the concave function $s\mapsto s^{m-1}$,
\begin{align} \label{lower semicty ineq 1}
 \F_\e(\mu_n) &= \frac{1}{m-1} \int (\varphi_\e *\mu_n)^{m-1} d \mu_n - \frac{1}{m-1} \int (\varphi_\e *\mu)^{m-1} d \mu_n + \frac{1}{m-1} \int (\varphi_\e *\mu)^{m-1} d \mu_n   \\
&\geq - \frac{1}{m-1} \int |\varphi_\e *(\mu_n - \mu)|^{m-1} d \mu_n +  \frac{1}{m-1} \int (\varphi_\e *\mu)^{m-1} d \mu_n \nonumber \\
&\geq - \frac{1}{m-1} \left(  \int |\varphi_\e *(\mu_n - \mu)| d \mu_n \right)^{m-1} +  \frac{1}{m-1} \int (\varphi_\e *\mu)^{m-1} d \mu_n \nonumber \\
&\geq - \frac{1}{m-1} \left(  \int |\zeta_\e *(\mu_n - \mu)| d \zeta_\e*\mu_n \right)^{m-1} +  \frac{1}{m-1} \int (\varphi_\e *\mu)^{m-1} d \mu_n . \nonumber
 \end{align}

 Since $\varphi_\e \in C_b(\Rd)$, $\mu_n \wsto \mu$ ensures that $\zeta_\e * \mu_n \to \zeta_\e* \mu \to 0$ pointwise. The integrand of the first term is bounded above by $2\|\zeta_\e\|_\infty^2$, so by the dominated convergence theorem, the first integral converges to zero. Since the integrand of the second term is continuous and bounded by $\|\varphi_\e\|_\infty^{m-1}$, the fact that $\mu_n \wsto \mu$ ensures this second term converges to $\F_\e(\mu)$. This gives the result.

 We conclude with the case $m > 2$. Inequality (\ref{lower semicty ineq 0}) ensures that $\F^m_\e(\mu_n) = \|\varphi_\e*\mu_n\|_{L^{m-1}(d \mu_n)} < C$ for all $n \in \mathbb{N}$, so by \cite[Theorem 5.4.4]{AGS}, there exists $v \in L^{m-1}(\mu)$ so that, up to another subsequence, 
 \begin{align} \label{lower semicty ineq 2} \liminf_{n \to +\infty} \|\varphi_\e*\mu_n\|_{L^{m-1}(d \mu_n)} \geq  \|v\|_{L^{m-1}(\mu)} \ \text{ and } \  \int f (\varphi_\e *\mu_n) d \mu_n \to \int f v d \mu,  \ \forall f \in C^\infty_c(\Rd). 
 \end{align}
 It suffices to show that $v \geq \varphi_\e*\mu$ $\mu$-almost everywhere. Then, the first inequality in (\ref{lower semicty ineq 2}) gives
 \[ \liminf_{n \to +\infty} \F^m_\e(\mu_n) = \liminf_{n \to +\infty} \|\varphi_\e*\mu_n\|_{L^{m-1}(d \mu_n)} \geq  \|v\|_{L^{m-1}(\mu)} \geq \|\varphi_\e*\mu \|_{L^{m-1}(\mu)} = \F_\e^m(\mu) . \]

Since $\mu_n \wsto \mu$ and $f, \zeta_\e \in C_b(\Rd)$, we have $\zeta_\e*( f \mu_n) \to \zeta_\e*( f \mu)$ and $\zeta_\e*\mu_n \to \zeta_\e *\mu$ pointwise.
Consequently, using that $\varphi_\e = \zeta_\e *\zeta_\e$ and Fatou's lemma, we obtain that for all $f \in C^\infty(\Rd)$, $f \geq 0$, 
\[ \liminf_{n \to +\infty} \int f (\varphi_\e *\mu_n) d \mu_n = \liminf_{n \to +\infty} \int \zeta_\e*( f \mu_n) \zeta_\e*\mu_n \geq \int \zeta_\e *(f \mu) \zeta_\e *\mu = \int f \varphi_\e* \mu d \mu .\]
Combining this with the second inequality in (\ref{lower semicty ineq 2}) gives
\[ \int f v d \mu \geq \int f \varphi_\e* \mu d \mu \quad \text{ for all } f \in C^\infty(\Rd), f \geq 0 .\]
Therefore, $v \geq \varphi_\e* \mu$ $\mu$-almost everywhere, which gives the result.
 \kcomment{Since \cite[Theorem 5.4.4]{AGS} plays a key role both here and in the $\Gamma$-convergence proof, it might make sense to recall its statement in the preliminaries section.}
 
\comment{$m=1$?}
Define the functional 
\bes	
	\tilde{\F}_\e^m(\mu) = \int_{\Rd} \frac{(\varphi_\e*\mu(x))^{m-1}-1}{m-1} \,d\mu(x) = \F_\e^m(\mu) - \frac{1}{m-1} \quad \mbox{for all $\mu\in\P_2(\Rd)$}.
\ees
Let $(m_k)_k$ be a sequence of numbers in $(1,\infty)$ such that $m_k \to 1$ as $k\to\infty$. By lower semicontinuity of $\F_\e^{m_k}$ for all $k\in\N$, we know that $\tilde{\F}_\e^{m_k}$ is also lower semicontinuous so that
\bes
	\liminf_{n\to\infty}\tilde{\F}_\e^{m_k}(\mu_n) \geq \tilde{\F}_\e^{m_k}(\mu).
\ees
By boundedness of $\varphi_\e*\mu$ the dominated Lebesgue theorem gives that $\tilde{\F}_\e^{m_k}(\mu) \to \F_\e^1(\mu)$ as $k\to\infty$. Hence
\bes	
\liminf_{k\to\infty}\liminf_{n\to\infty}\tilde{\F}_\e^{m_k}(\mu_n) \geq \F_\e^1(\mu).
\ees
\comment{If the liminf operators can be swapped}, then 
\bes
\liminf_{n\to\infty}\liminf_{k\to\infty}\tilde{\F}_\e^{m_k}(\mu_n) = \liminf_{n\to\infty} \F_\e^1(\mu_n) \geq \F_\e^1(\mu),
\ees
which the result.
\end{proof}

\begin{lem}[differentiability] \label{diff lem}
	Let $F$ be nondecreasing. Let $(\mu_\alpha^{2\to3})_{\alpha\in[0,1]}$ be a generalized geodesic connecting two probability measures $\mu_2,\mu_3\in\P_2(\R^d)$ with base $\mu_1\in\P_2(\R^d)$. That is, $\mu_\alpha^{2\to3} = \left((1-\alpha)\pi^2+\alpha\pi^3\right)_\# \bgamma$ for all $\alpha \in[0,1]$ where $\bgamma\in\Gamma(\mu_1,\mu_2,\mu_3)$. Then
\begin{equation} \label{diff lem eqn} 
	\begin{split}
		&\left. \frac{d}{d \alpha } \F^m_\e(\mu_\alpha^{2\to3}) \right|_{\alpha = 0}\\
		&=\iiint \iiint F'\left(\varphi_\e*\mu_2(y) \right) \grad \varphi_\e(y-v) \cdot (z-w-(y-v)) \,d \bgamma(u,v,w)\, d \bgamma(x,y,z). 
	\end{split}
\end{equation}
\end{lem}

\begin{proof}
	By definition, for all $\alpha \in[0,1]$,
\bes
	\F_\e(\mu_\alpha^{2\to3}) = \iint F\left(\varphi_\e * \mu_\alpha((1-\alpha)x + \alpha y)\right) \,d\gamma(x,y).
\ees
Therefore
\begin{equation}   \label{diff eqn0}
	\begin{split}
	&\F_\e(\mu_\alpha^{2\to3}) - \F_\e(\mu_2)\\
	&= \iiint\left(  F\left(\varphi_\e * \mu_\alpha^{2\to3}((1-\alpha)y + \alpha z))\right) - F\left(\varphi_\e * \mu_1(y)\right)  \right) \,d \bgamma(x,y,z)\\
	&= \int_0^1 \iiint F'(c_{s,\alpha}(y,z)) \left( \varphi_\e * \mu_\alpha^{2\to3}((1-\alpha)y + \alpha z)) - \varphi_\e * \mu_1(y) \right) \,d\bgamma(x,y,z) \,ds,
	\end{split}
\end{equation}
where $c_{s,\alpha}(y,z) = (1-s)\varphi_\e*\mu_1(y) + s\varphi_\e*\mu_\alpha^{2\to3}((1-\alpha)y + \alpha x)$. Using Taylor's theorem compute
\begin{align*}
	&\varphi_\e * \mu_\alpha^{2\to3}((1-\alpha)y + \alpha z)) - \varphi_\e * \mu_1(y)\\
	&= \iiint \left( \varphi_\e((1-\alpha) (y-v) + \alpha (z-w)) - \varphi_\e*(y-v) \right) \,d\bgamma(u,v,w)\\
	&= \iiint \left( \alpha \grad \varphi_\e(y-v) \cdot (z-w - (y-v)) + D_\alpha(y,z,v,w)\right) \,d\bgamma(u,v,w),
\end{align*}
where $D_\alpha(y,z,v,w)$ is a term depending on the Hessian of $\varphi_\e$ satisfying
\begin{align*}
	\left|\iiint  D_\alpha(y,z,v,w) \,d\bgamma(u,v,w)\right| &\leq \frac{\alpha^2}{2} \norm{D^2\varphi_\e}_\infty \iint |z-w-(y-v)|^2 \,d\bgamma(u,v,w)\\
	&\leq 2\alpha^2 \norm{D^2\varphi_\e}_\infty \left( |z|^2 + |y|^2 + \int |w|^2\,d\mu_3(w)+\int|v|^2 \,d\mu_2(v) \right)
\end{align*}
Hence, since $F'$ is nondecreasing,
\begin{align*}
	&\F_\e(\mu_\alpha^{2\to3}) - \F_\e(\mu_2)\\
	 &= \alpha \int_0^1 \iiint \iiint F'(c_{s,\alpha}(y,z)) \grad \varphi_\e(y-v) \cdot (z-w-(y-v)) \,d\bgamma(u,v,w) \,d\bgamma(x,y,z)\,ds + C_\alpha, 
\end{align*}
where $|C_\alpha| \leq 4\alpha^2 \|D^2\varphi_\e\|_\infty F'( \|\varphi_\e\|_\infty) (\int |x|^2 \,d\mu_2(x) + \int |x|^2 \,d\mu_3(x))$. Note that $c_{s,\alpha}(y,z)$ converges pointwise to $\varphi_\e*\mu_2(y)$ as $\alpha\to0$ since
\begin{align*} 
	&\left|\varphi_\e * \mu_\alpha^{2\to3}((1-\alpha)y +\alpha z) - \varphi_\e * \mu_2(y) \right|\\
	&= \left|\iiint \left(\varphi_\e((1-\alpha)(y-v) + \alpha (z - w)) - \varphi_\e(y-v) \right) \,d \bgamma(u,v,w) \right|\\
	& \leq \alpha \|\grad \varphi_\e\|_\infty \left( |z|+|y| + \int |w| \,d\mu_3(w) + \int |v| \,d\mu_2(v) \right).
\end{align*}
Thus, to complete the result, it suffices to show that there exists $g \in L^1(\bgamma \otimes \bgamma)$ so that 
\[
	F'(c_{s,\alpha}(y,z)) \left| \grad \varphi_\e(y-v) \cdot (z-w-(y-v))  \right| \leq g(y,z,v,w),
\]
since the result then follows by the dominated convergence theorem. Since $F'$ is nondecreasing we may take
\bes
	g(y,z,v,w) = F'\left(\norm{\varphi_\e}_\infty\right) \norm{\grad \varphi_\e}_\infty |z-w-(y-v)|, 
\ees
which ends the proof.
\end{proof}


%\begin{lem}[differentiability] \label{diff lem}
%	Let $F$ be nondecreasing. Let $(\mu_\alpha)_{\alpha\in[0,1]}$ be a geodesic connecting two probability measures $\mu_0,\mu_1\in\P_2(\R^d)$ such that $\mu_0,\mu_1\in D(\F_\e)$. That is, $\mu_\alpha = \left((1-\alpha)\pi_1+\alpha\pi_2\right)_\# \gamma$ for all $\alpha \in[0,1]$ where $\gamma\in\P(\R^d\times\R^d)$ is an optimal transport plan between $\mu_0$ and $\mu_1$. Then
%\begin{equation} \label{diff lem eqn} 
%	\left. \frac{d}{d \alpha } \F^m_\e(\mu_\alpha) \right|_{\alpha = 0}=\iint \iint \grad \varphi_\e(x-z) \cdot (y-w-(x-z))  F'\left(\varphi_\e*\mu_0(x) \right) \,d \gamma(z,w)\, d \gamma(x,y). 
%\end{equation}
%\end{lem}
%
%\begin{proof}
%	By definition, for all $\alpha \in[0,1]$,
%\bes
%	\F_\e(\mu_\alpha) = \iint F\left(\varphi_\e * \mu_\alpha((1-\alpha)x + \alpha y)\right) \,d\gamma(x,y).
%\ees
%Therefore
%\begin{equation}   \label{diff eqn0}
%	\begin{split}
%	\F_\e(\mu_\alpha) - \F_\e(\mu_0) &= \iint\left(  F\left(\varphi_\e * \mu_\alpha((1-\alpha)x + \alpha y))\right) - F\left(\varphi_\e * \mu_0(x)\right)  \right) \,d \gamma(x,y)\\
%	&= \int_0^1 \iint F'(c_s(x,y)) \left( \varphi_\e * \mu_\alpha((1-\alpha)x + \alpha y)) - \varphi_\e * \mu_0(x) \right) \,d\gamma(x,y) \,ds,
%	\end{split}
%\end{equation}
%where $c_s(x,y) = (1-s)\varphi_\e*\mu_0(x) + s\varphi_\e*\mu_\alpha((1-\alpha)x + \alpha y)$. Using Taylor's theorem compute
%\begin{align*}
%	&\varphi_\e * \mu_\alpha((1-\alpha)x + \alpha y)) - \varphi_\e * \mu_0(x)\\
%	&= \iint \left( \varphi_\e((1-\alpha) (x-z) + \alpha (y-w)) - \varphi_\e*(x-z) \right) \,d\gamma(z,w)\\
%	&= \iint \left( \alpha \grad \varphi_\e(x-z) \cdot (y-w - (x-z)) + D_\alpha(x,y,z,w)\right) \,d\gamma(z,w),
%\end{align*}
%where $D_\alpha(x,y,z,w)$ is a term depending on the Hessian of $\varphi_\e$ satisfying
%\begin{align*}
%	\left|\iint  D_\alpha(x,y,z,w) \,d\gamma(z,w)\right| &\leq \frac{\alpha^2}{2} \norm{D^2\varphi_\e}_\infty \iint |y-w-(x-z)|^2 \,d\gamma(z,w)\\
%	&\leq 2\alpha^2 \norm{D^2\varphi_\e}_\infty \left( |x|^2 + |y|^2 + \int |w|^2\,d\mu_1(w)+\int|z|^2 \,d\mu_0(z) \right)
%\end{align*}
%Hence, since $F$ is nondecreasing,
%\begin{align*}
%	\F_\e(\mu_\alpha) - \F_\e(\mu_0) &= \alpha \int_0^1 \iint \iint F'(c_s(x,y)) \grad \varphi_\e(x-z) \cdot (y-w-(x-z)) \,d\gamma(z,w) \,d\gamma(x,y)\,ds\\
%	&\phantom{{}={}} + C_\alpha, 
%\end{align*}
%where $|C_\alpha| \leq 4\alpha^2 \|D^2\varphi_\e\|_\infty F'( \|\varphi_\e\|_\infty) (\int |x|^2 \,d\mu_0(x) + \int |x|^2 \,d\mu_1(x))$. Note that $c_s(x,y)$ converges pointwise to $\varphi*\mu_0(x)$ as $\alpha\to0$ since
%\begin{align*} 
%	&\left|(\varphi_\e * \mu_\alpha)((1-\alpha)x +\alpha y) - (\varphi_\e * \mu_0)(x) \right|\\
%	&= \left|\iint \left(\varphi_\e((1-\alpha)(x-z) + \alpha (y - w)) - \varphi_\e(x-z) \right) \,d \gamma(z,w) \right|\\
%	& \leq \alpha \|\grad \varphi_\e\|_\infty \left( \int |w| \,d\mu_1(w) + \int |z| \,d\mu_0(z) \right) (|x|+|y|).
%\end{align*}
%Thus, to complete the result, it suffices to show that there exists $g \in L^1(\gamma \otimes \gamma)$ so that 
%\[
%	F'(c_s(x,y)) \left| \grad \varphi_\e(x-z) \cdot (y-w-(x-z))  \right| \leq g(x,y,z,w),
%\]
%since the result then follows by the dominated convergence theorem. Since $F$ is nondecreasing we may take
%\bes
%	g(x,y,z,w) = F'\left(\norm{\varphi_\e}_\infty\right) \norm{\grad \varphi_\e}_\infty | y-w-(x-z)|, 
%\ees
%and the proof ends.
%\end{proof}

%\begin{lem}[differentiability] \label{diff lem}
%Suppose $\mu_\alpha = (\id + \alpha \bxi)\# \mu$ for $\mu  \in D(\F^m_\e)$, $\alpha \in \R$, and $\bxi : \Rd \to \Rd$. When $1 \leq m < 2$, suppose $\bxi$ is smooth and compactly supported and $\int |x| d \mu < +\infty$.When $m \geq 2$, suppose that $\bxi \in L^2(\mu)$. Then
%\begin{align} \label{diff lem eqn}  \left. \frac{d}{d \alpha } \F^m_\e(\mu_\alpha) \right|_{\alpha = 0}= \iint \grad \varphi_\e(x-y) \cdot (\bxi(x) - \bxi(y))  \left(\varphi_\e*\mu(x) \right)^{m-2} d \mu(y)  \,d \mu(x). 
%\end{align}
%\end{lem}
%
%\begin{proof}
%By definition,
%\begin{align}   \label{diff eqn0}
%\frac{1}{\alpha} \left( \F^m_\e(\mu_\alpha) - \F^m_\e(\mu) \right) &= \frac{1}{\alpha(m-1)} \left( \int (\varphi_\e * \mu_\alpha)^{m-1}d \mu_\alpha -  \int (\varphi_\e * \mu)^{m-1} d \mu \right)   \\
%&= \frac{1}{\alpha (m-1)} \left( \int  (\varphi_\e * \mu_\alpha) \circ (\id + \alpha \bxi)^{m-1} - (\varphi_\e * \mu)^{m-1} d \mu \right) . \nonumber
%\end{align}
%By the fundamental theorem of calculus, we may rewrite the integrand in the above equation as
%\begin{align} \label{diff eqn1}
%&\frac{1}{\alpha(m-1)} \left[(\varphi_\e * \mu_\alpha) \circ (\id + \alpha \bxi)^{m-1} - (\varphi_\e * \mu)^{m-1} \right] \\
%&= \frac{1}{\alpha} \int_0^1 \left[(1-s)(\varphi_\e * \mu) + s(\varphi_\e * \mu_\alpha) \circ (\id + \alpha \bxi) \right]^{m-2} \left[(\varphi_\e * \mu_\alpha) \circ (\id + \alpha \bxi) - (\varphi_\e * \mu) \right] ds . \nonumber
%\end{align}
%For all $x \in \Rd$, Taylor's theorem ensures
%\begin{align*}
%&\left| \frac{1}{\alpha}\left[(\varphi_\e * \mu_\alpha)(x + \alpha \bxi(x)) - (\varphi_\e * \mu)(x) \right] - \int \grad \varphi_\e(x-y) \cdot (\bxi(x) - \bxi(y)) d\mu(y) \right| \\   
%&= \frac{1}{\alpha} \left| \int \varphi_\e(x + \alpha \bxi(x)-y - \alpha \bxi(y)) - \varphi_\e(x-y)- \alpha \grad \varphi_\e(x-y) \cdot (\bxi(x) - \bxi(y)) d \mu(y)  \right| \\ 
%&\leq \alpha \|D^2 \varphi_\e \|_\infty \int |\bxi(x) - \bxi(y)|^2 d \mu(y) \\
%&\leq 2\alpha \|D^2 \varphi_\e \|_\infty \|\bxi\|^2_{L^2(d\mu)} |\bxi(x)|^2
%\end{align*}
%Combining this with equations (\ref{diff eqn0}) and (\ref{diff eqn1}) gives
%\begin{align*} \label{diff eqn2}
%&\frac{1}{\alpha} \left( \F^m_\e(\mu_\alpha) - \F^m_\e(\mu) \right) \\
%&= \int_0^1  \iint \left[(1-s)(\varphi_\e * \mu)(x) + s(\varphi_\e * \mu_\alpha)(x + \alpha \bxi(x)) \right]^{m-2}  \grad \varphi_\e(x-y) \cdot (\bxi(x) - \bxi(y)) d\mu(y)  d \mu(x)  ds + C_\alpha \nonumber
%\end{align*}
%where $|C_\alpha| \leq 4\alpha \|D^2 \varphi_\e \|_\infty \|\varphi_\e\|_\infty \|\bxi\|^2_{L^2(d\mu)} $.
%Note that the term in the brackets converges pointwise to $(\varphi_\e*\mu)(x)$ as $\alpha \to 0$ since
%\begin{align*} \left|(\varphi_\e * \mu_\alpha)(x + \alpha \bxi(x)) - (\varphi_\e * \mu)(x) \right| &= \left|\int \varphi_\e(x + \alpha \bxi(x) - y - \alpha \bxi(y)) - \varphi_\e(x-y) d \mu(y) \right| \\
%&\leq \alpha \|\grad \varphi_\e\|_\infty \|\bxi\|_{L^2(d\mu)} |\bxi(x)|.
%\end{align*}
%Thus, to complete the result, it suffices to show that there exists $g(x,y) \in L^1(\mu \otimes \mu)$ so that 
%\[\left| \left[(1-s)(\varphi_\e * \mu)(x) + s(\varphi_\e * \mu_\alpha)(x + \alpha \bxi(x)) \right]^{m-2}  \grad \varphi_\e(x-y) \cdot (\bxi(x) - \bxi(y)) \right| \leq g(x,y) , \]
%since the result then follows by the dominated convergence theorem.
%
%We consider the cases $1 \leq m < 2$ and $m \geq 2$ separately. When $m\geq 2$, we may take
%\[ g(x,y) = \|\varphi_\e\|_\infty^{m-2} \|\grad \varphi_\e \|_\infty \left| \bxi(x) - \bxi(y) \right| .\]
%When $1 \leq m <2$, we may use the fact that $\xi$ is smooth and compactly supported to conclude that there exists $R>0$ so that $|\bxi(x)| \leq \|\bxi\|_\infty 1_{B_R(0)}$, where $1_{B_R(x)}$ denotes the indicator function on a ball of radius $R>0$. Since $\varphi_\e*\mu(x)$ is continuous and positive, $\min_{B_R(0)} \varphi_\e*\mu(x)  = a>0$. Then, for all $0<\alpha < a/(2\|\varphi_\e\|_\infty \|\bxi\|_\infty^2)$, we may take
%\[ g(x,y) = \|\bxi\|_\infty \left(\frac{1}{2}\varphi_\e*\mu(x) \right)^{m-2}  |\grad \varphi_\e(x-y) |(1_{B_R(0)}(x) + 1_{B_R(0)}(y)) .\]
%To see that $g(x,y) \in L^1(d \mu(x), d \mu(y))$, we consider the terms corresponding to $1_{B_R(0)}(x)$ and $1_{B_R(0)}(y)$ separately. For the former, we have that 
%\[ \left(\frac{1}{2}\varphi_\e*\mu(x) \right)^{m-2} |\grad \varphi_\e(x-y) | \leq \left(\frac{a}{2} \right)^{m-2} \|\grad \varphi_\e\|_\infty , \] 
%so the term is integrable. For the $1_{B_R(0)}(y)$ term, note that
%\begin{align*} \int \left(\frac{1}{2}(\varphi_\e*\mu)(x) \right)^{m-2}  |\grad \varphi_\e(x-y)| 1_{B_R(y)} d \mu(y) &= \frac{1}{2^{m-1}\e^2} (\varphi_\e*\mu)(x)^{m-2} \int |x-y|\varphi_\e(x-y) 1_{B_R(y)}  d \mu(y) \\
%&\leq \frac{1}{2^{m-1}\e^2} (\varphi_\e*\mu)(x)^{m-1} \left(|x| + R \right) \\
%&\leq \frac{\|\varphi_\e*\mu\|^{m-1}_\infty}{2^{m-1}\e^2}  \left(|x| + R \right) .
%\end{align*}
%Finally, we use that $\int |x| d \mu(x) < +\infty$ to conclude that the integral of the above quantity is bounded. This completes the proof.
%\end{proof}

We now use the previous results to characterize the subdifferential of $\F^m_\e$. The argument is standard, and we include it for completeness (c.f. \cite{JKO, 5person, AGS}).
\begin{prop}[characterization of subdifferential] \label{subdiffchar}
	Let $m \geq 1$ and $\e >0$, and let $\mu \in D(\F_\e^m)$. Then
\bes
	v \in \partial \F^m_\e(\mu) \cap \Tan_\mu\P_2(\R^d) \iff v = \grad \frac{\delta \F_\e^m}{\delta \mu},
\ees
where we recall that the first variation density of $\F_\e^m$ is given by
\be \label{subdiffform} 
	\grad \frac{\delta \F_\e^m}{\delta \mu} = \grad \varphi_\e* \left((\varphi_\e*\mu)^{m-2} \mu \right) + (\varphi_\e* \mu)^{m-2} (\grad \varphi_\e * \mu).
\ee
In particular, we have
\begin{align*}
|\partial \F^m_\e|(\mu) = \left\|\grad \frac{\delta \F_\e^m}{\delta \mu} \right\|_{L^2(d \mu)}
\end{align*}
\end{prop}

\begin{proof}
Suppose $v \in \partial \F^m_\e (\mu)$. Fix $\psi \in C^\infty_c(\Rd)$ and define $\mu_\alpha = (\id + \alpha \grad \psi) \# \mu$. For $\alpha$ sufficiently small, $x^2/2+ \alpha \psi(x)$ is convex and $\id + \alpha \grad \varphi$ is the optimal transport map from $\mu$ to $\mu_\alpha$, so $\Gamma_0(\mu,\mu_\alpha) = \{\id \times (\id + \alpha \grad \psi) \}$. Since $v \in \partial \F^m_\e (\mu)$, taking $\nu = \mu_\alpha$ in Definition \ref{subdiffdef} of the subdifferential, for $\alpha$ sufficiently small, gives
\[ \F^m_\e(\mu_\alpha) - \F^m_\e(\mu) \geq  \int \la v,\alpha \grad \psi \ra d \mu + o(\alpha \|\grad \psi\|_{L^2(\mu)}) . \]
Combining this with Lemma \ref{diff lem}, we obtain
\[ \int \la v, \grad \psi \ra d \mu \leq \lim_{\alpha \to 0^+} \frac{\F^m_\e(\mu_\alpha) - \F^m_\e(\mu)}{\alpha} = \left. \frac{d}{d\alpha} \F^m_\e(\mu_\alpha) \right|_{\alpha = 0} = \lim_{\alpha \to 0^-} \frac{\F^m_\e(\mu_\alpha) - \F^m_\e(\mu)}{\alpha} \leq \int \la v, \grad \psi \ra d \mu .\]

Rewriting the expression from equation (\ref{diff lem eqn}) gives
\[ \int \la v, \grad \psi \ra d \mu = \left. \frac{d}{d\alpha} \F^m_\e(\mu_\alpha) \right|_{\alpha = 0} = \int \left\langle   \grad \varphi_\e* \left((\varphi_\e*\mu)^{m-2} \mu \right) + (\varphi_\e* \mu)^{m-2} (\grad \varphi_\e * \mu), \grad \psi  \right \rangle d \mu .\]
Thus, for $w = v - \grad \varphi_\e* \left((\varphi_\e*\mu)^{m-2} \mu \right) + (\varphi_\e* \mu)^{m-2} (\grad \varphi_\e * \mu)$, we have $\int \la w , \grad \psi \ra d \mu = 0$, i.e. $\grad \cdot (w \mu) = 0$ in the sense of distribution.

Now, suppose $v$ is given by equation (\ref{subdiffform}). The rest of this proof is closely inspired by that of \cite[Proposition 2.2]{5person}. For all $x,y \in \R^d$ define $G(\alpha) = F(\varphi_\e*\mu_\alpha((1-\alpha)x + \alpha y))$ for all $\alpha \in [0,1]$, where $\mu_\alpha = ((1-\alpha)\pi^1 + \alpha \pi^2)_\#\gamma$, with some $\gamma \in \Gamma_\mathrm{o}(\mu,\mu_1)$, connects $\mu_0=\mu$ and $\mu_1$. Now define
\bes
	f(\alpha) = \frac{G(\alpha) - G(0)}{\alpha} - \frac{\lambda \alpha}{2}|x-y|^2 \quad \mbox{for all $\alpha \in [0,1]$,}
\ees
where \comment{$\lambda = 4F'(\|\varphi_\e\|_\infty)\|D^2\varphi_\e\|_\infty$}. We write $[a,b]_\alpha := (1-\alpha)a +\alpha b$ for any $a,b\in\R^d$. Let us compute the first two derivatives of $G$ for all $\alpha \in [0,1]$:
\be\label{eq:G'}
	G'(\alpha) = F'(\varphi_\e*\mu_\alpha([x,y]_\alpha) \irdrd (y-x  + u-v) \cdot \nabla \varphi_\e([x-u,y-v]_\alpha)\,d\gamma(u,v),
\ee
and
\begin{align*}
	G''(\alpha) &= F''(\varphi_\e*\mu_\alpha([x,y]_\alpha) \left( \irdrd (y-x  + u-v) \cdot \nabla \varphi_\e([x-u,y-v]_\alpha)\,d\gamma(u,v) \right)^2\\
	&\phantom{{}={}}+ F'(\varphi_\e*\mu_\alpha([x,y]_\alpha) \irdrd (y-x  + u-v) D^2\varphi_\e([x-u,y-v]_\alpha)(y-x  + u-v) \,d\gamma(u,v).
\end{align*}
Clearly, by Taylor's theorem, 
\bes
	f(\alpha) = G'(0) + \int_0^\alpha \frac{\alpha-s}{\alpha} G''(s) \,d s - \frac{\lambda \alpha}{2}|x-y|^2.
\ees
By convexity of $F$ and monotonicity of $F'$, $G''(\alpha) \geq \lambda |x-y|^2$. \comment{(F: Double-check this.)} Therefore
\bes
	f'(\alpha) = \frac{1}{\alpha^2} \int_0^\alpha sG''(s) \,ds - \frac{\lambda}{2}|x-y|^2 \geq 0,
\ees
which shows that $f$ is nondecreasing, and so $f(1) \geq \lim_{\alpha \to 0} f(\alpha)$, which implies (after integrating against $d\gamma(x,y)$)
\begin{align*}
	\F_\e(\mu_1) - \F_\e(\mu_0) &\geq \irdrd \lim_{\alpha \to 0} \left(\frac{G(\alpha) - G(0)}{\alpha} - \frac{\lambda \alpha}{2}|x-y|^2\right) \,d\gamma(x,y) + \frac{\lambda}{2}W_2^2(\mu_0,\mu_1)\\
	&= \irdrd G'(0) \,d\gamma(x,y) + \frac{\lambda}{2}W_2^2(\mu_0,\mu_1).
\end{align*}
Then, by \eqref{eq:G'} and antisymmetry of $\nabla \varphi_\e$, compute
\begin{align*}
	\irdrd G'(0) \,d\gamma(x,y) &= \irdrd \irdrd  F'(\varphi_\e*\mu_0(x)) (y-x  + u-v) \cdot \nabla \varphi_\e(x-u)\,d\gamma(u,v) \,d\gamma(x,y)\\
	&= \irdrd F'(\varphi_\e*\mu_0(x)) \nabla\varphi_\e*\mu_0(x)\cdot(y-x)\,d\gamma(x,y)\\
	&\phantom{{}={}} + \irdrd \nabla\varphi_\e* (F'\circ (\varphi_\e*\mu_0)\mu_0)(u) \cdot (v-u) \,d\gamma(u,v)\\
	&= \irdrd \nabla \frac{\delta \F_\e}{\delta \mu_0}(x) \cdot (y-x) \,d\gamma(x,y).
\end{align*}
Hence 
\bes
	\F_\e(\mu_1) - \F_\e(\mu_0) \geq \irdrd \nabla \frac{\delta \F_\e}{\delta \mu_0}(x) \cdot (y-x) \,d\gamma(x,y) + \frac{\lambda}{2}W_2^2(\mu_0,\mu_1),
\ees
which shows that $\delta \F_\e/\delta \mu_0 \in \partial  \F_\e(\mu_0)$. We now prove that $v \in \Tan_\mu\P_2(\R^d)$. Consider a vector-valued function $\boldsymbol{\xi} \in C_\mathrm{c}^\infty(\R^d)^d$, and for any $x,y\in\R^d$ define $H(\alpha) = F(\ird \varphi_\e(x-y + \alpha(\boldsymbol{\xi}(x) - \boldsymbol{\xi}(y))\,d\mu(y)))$ for all $\alpha\in[0,1]$. Then
\bes
	H'(0) = F'(\varphi_\e*\mu(x)) \ird (\boldsymbol{\xi}(x) - \boldsymbol{\xi}(y)) \cdot \nabla \varphi_\e(x-y) \,d\mu(y).
\ees
Now compute, using the antisymmetry of $\nabla \varphi_\e$,
\begin{align*}
	\lim_{\alpha \to0} \frac{\F_\e((\id + \alpha \boldsymbol{\xi})_\#\mu) - \F_\e(\mu)}{\alpha} &= \lim_{\alpha\to0} \ird \frac{H(\alpha)-H(0)}{\alpha} \,d\mu(x) = \ird H'(0) \,d\mu(x)\\
	&= \ird F'(\varphi_\e*\mu(x)) \nabla \varphi_\e*\mu(x) \cdot \boldsymbol{\xi}(x) \,d\mu(x)\\
	&\phantom{{}={}}+ \ird \nabla\varphi_\e * (F'\circ(\varphi_\e*\mu)\mu)(x) \cdot \boldsymbol{\xi}(x) \,d\mu(x)\\
	&= \ird \nabla \frac{\delta \F_\e}{\delta \mu}(x) \cdot \boldsymbol{\xi}(x) \, d\mu(x).
\end{align*}
\comment{(F: Check we can pass limit inside integral in first line.)} Then, by the definition of the local slope of $\F_\e$ \comment{(F: Add definition)},
\bes
	\liminf_{\alpha \to 0} \frac{\F_\e((\id + \alpha \boldsymbol{\xi})_\#\mu) - \F_\e(\mu)}{W_2((\id + \alpha \boldsymbol{\xi})_\#\mu,\mu)} \geq - |\partial \F_\e|(\mu).
\ees
Therefore, by the previous computation,
\bes
	\ird \nabla \frac{\delta \F_\e}{\delta \mu}(x) \cdot \boldsymbol{\xi}(x) \, d\mu(x) \geq -|\partial \F_\e|(\mu) \liminf_{\alpha\to0} \frac{W_2((\id + \alpha \boldsymbol{\xi})_\#\mu,\mu)}{\alpha} \geq -|\partial \F_\e|(\mu) \|\boldsymbol{\xi}\|_{L^2_\mu(\R^d)},
\ees
since, by definition of the 2-Wasserstein distance,
\bes
	\limsup_{\alpha\to0}  \frac{W_2((\id + \alpha \boldsymbol{\xi})_\#\mu,\mu)}{\alpha} \leq \|\boldsymbol{\xi}\|_{L^2_\mu(\R^d)}.
\ees
Then, by replacing $\boldsymbol{\xi}$ with $-\boldsymbol{\xi}$ and by arbitrariness of $\boldsymbol{\xi}$ \comment{(F: Are we taking $\boldsymbol{\xi} = v$? What if $v$ is not compactly supported?)}, we get
\bes
	\left\| \nabla \frac{\delta \F_\e}{\delta\mu}\right\|_{L^2_\mu(\R^d)} \leq |\partial \F_\e|(\mu),
\ees
which shows the desired result.
{\color{Aquamarine} Need to close proof by explaining why this gives the formula for the metric slope }
\end{proof}


When $F(s)$ is convex, we have the following estimate on the convexity of the regularized energies.
\begin{prop}\label{thm:conv}
	Let $F'$ be nondecreasing. Then $\F_\e$ is $\lambda$-convex along generalized geodesics in $\P_2(\Rd)$, where $\lambda = - 4 \|D^2 \varphi_\e \|_\infty F'(\|\varphi_\e\|_\infty)$.
\end{prop}

\begin{proof}
	 Let $(\mu_\alpha^{2\to3})_{\alpha\in[0,1]}$ be a generalized geodesic connecting two probability measures $\mu_2,\mu_3\in\P_2(\R^d)$ with base $\mu_1\in\P_2(\R^d)$. That is, $\mu_\alpha^{2\to3} = \left((1-\alpha)\pi^2+\alpha\pi^3\right)_\# \bgamma$ for all $\alpha \in[0,1]$ with ${\pi^{1,2}}_\#\bgamma\in\Gamma_\mathrm{o}(\mu_1,\mu_2)$ and ${\pi^{1,3}}_\#\bgamma\in\Gamma_\mathrm{o}(\mu_1,\mu_3)$. We have, using \eqref{tangent line convex},
\begin{align*}
	\F_\e(\mu_3) - \F_\e(\mu_2) &= \iiint \left(F(\varphi_\e*\mu_3)(y) - F(\varphi_\e*\mu_2)(z) \right)  \,d\bgamma(x,y,z)\\
	&\geq \iiint F'(\varphi_\e*\mu_2(y)) \left( \varphi_\e*\mu_3(z) - \varphi_\e*\mu_2(y) \right)\,d\bgamma(x,y,z) \\
	&= \iiint \iiint F'(\varphi_\e*\mu_2(y)) \left( \varphi_\e(z-w) - \varphi_\e(y-v) \right)\,d\bgamma(u,v,w)\,d\bgamma(x,y,z).
\end{align*}
Therefore, by Lemma \ref{diff lem},
\begin{align*}
	&\F_\e(\mu_3) - \F_\e(\mu_2) - \left. \frac{d}{d \alpha}\F_\e(\mu_\alpha^{2\to3}) \right|_{\alpha = 0} \\
 	&\geq \iiint \iiint F'(\varphi_\e*\mu_2(y)) \\
 	&\phantom{{}={}}\times \left[ \varphi_\e(z-w) - \varphi_\e(y-v) - \grad \varphi_\e(y-v) \cdot (z-w-(y-v)) \right]\,d \bgamma(u,v,w)\,d \bgamma(x,y,z)\\
	&\geq -\frac{\|D^2 \varphi_\e\|_\infty}{2} \iiint \iiint F'(\varphi_\e*\mu_2(y)) |z-w - (y-v)|^2 \,d \bgamma(u,v,w)\,d \bgamma(x,y,z) \\
	&\geq -\frac{\|D^2 \varphi_\e\|_\infty F'(\|\varphi_\e\|_\infty)}{2} \iiint \iiint |z-w - (y-v)|^2\,d \bgamma(u,v,w)\,d \bgamma(x,y,z) \\
	&\geq -4\|D^2 \varphi_\e\|_\infty F'(\|\varphi_\e\|_\infty) W_{2,\bgamma}^2(\mu_2,\mu_3),
 \end{align*}
where 
\bes
	W_{2,\bgamma}^2(\mu_2,\mu_3) = \iiint |y-z|^2 \,d\bgamma(x,y,z).
\ees
This gives the result.
\end{proof}

%\begin{prop}\label{thm:conv}
%For $m \geq 2$ and $\e >0$, $\F^m_\e(\mu)$ is $\lambda$-convex along \kcomment{generalized} geodesics in $\P_2(\Rd)$, where $\lambda = - 4 \|D^2 \varphi_\e \|_\infty \|\varphi_\e\|_\infty^{m-2}$.
%\end{prop}
%%Let $F\colon[0,\infty)\to\R$ be continuously differentiable, nondecreasing, convex function and let $\phi\colon\R^d\to\R$ be a smooth, nonnegative, bounded, $\lambda$-convex function with $\lambda\leq0$. Then the functional defined by
%%\bes
%%	\F(\mu) = \ird F(\phi*\mu(x))\,d\mu(x) \quad \mbox{for all $\mu\in\P_2(\R^d)$}
%%\ees
%%is $\lambda_R$-convex along geodesics in $\P_R(\R^d)$, where $\lambda_R=4\lambda F'\left(\|\phi\|_\infty - 4\lambda R^2 \right)$.
%%\end{lem}
%\begin{proof}
%%	Let $\mu_0,\mu_1\in\P_R(\R^d)$ and 
%%\bes
%%	\mu_\alpha=\left((1-\alpha) \mathrm{id} + \alpha t\right)\# \mu_0 \quad \mbox{for all $\alpha\in[0,1]$},
%%\ees
%%where $t$ is the optimal map between $\mu_0$ and $\mu_1$, is the geodesic between $\mu_0$ and $\mu_1$. Write $[x,y] := x-y$ for any $x,y\in\R^d$, $\beta := 1-\alpha$, and $\phi_0 := \phi*\mu_0$ and $\phi_1 := \phi*\mu_1$. For any $\alpha\in[0,1]$, compute
%%\begin{align*}
%%	\F(\mu_\alpha) &= \ird F\left( \ird \phi\left( \beta[x,y] + \alpha[t(x),t(y)] \right)\,d\mu_0(y) \right) \,d\mu_0(x)\\
%%	&\leq \ird F\left( \beta\phi_0(x) + \alpha \phi_1(t(x)) - \frac{\lambda}{2}\alpha\beta\ird |[x-t(x),y-t(y)]|^2 \,d\mu_0(y) \right) \,d\mu_0(x)\\
%%	&\leq \beta \F(\mu_0) + \alpha \F(\mu_1) - \ird \Bigg[F'\left( \beta \phi_0(x) + \alpha \phi_1(t(x)) - \frac{\lambda}{2}\alpha\beta\ird |[x-t(x),y-t(y)]|^2 \,d\mu_0(y) \right)\\
%%	&\phantom{{}\leq{}} \times \frac{\lambda}{2}\alpha\beta\ird |[x-t(x),y-t(y)]|^2 \,d\mu_0(y) \Bigg]\,d\mu_0(x),
%%\end{align*}
%%where the second line is obtained using the $\lambda$-convexity of $\phi$, the monotonicity of $F$, and the third line using the convexity of $F$. Clearly $\phi_0,\phi_1\leq\|\phi\|_\infty$ and
%%\bes
%%	\ird |[x-t(x),y-t(y)]|^2 \,d\mu_0(y) \leq 2|x-t(x)|^2 + 2 W_2^2(\mu_0,\mu_1) \leq 8R^2.
%%\ees
%%Then, since $F'\geq0$, $F'$ is nondecreasing, $\lambda\leq0$ and $\alpha\beta\leq1$,
%%\begin{align*}
%%	\F(\mu_\alpha) &\leq \beta \F(\mu_0) + \alpha \F(\mu_1) - \frac{\lambda}{2}\alpha\beta \ird F'\left(\|\phi\|_\infty - 4\lambda\alpha\beta R^2 \right)\left(2|x-t(x)|^2 + 2 W_2^2(\mu_0,\mu_1)\right)\,d\mu_0(x)\\
%%	&\leq \beta \F(\mu_0) + \alpha \F(\mu_1) - 2\lambda\alpha\beta F'\left(\|\phi\|_\infty - 4\lambda R^2 \right)W_2^2(\mu_0,\mu_1),
%%\end{align*}
%%which ends the proof.
%\kcomment{Check out this new proof. Does this work?!?!}
%A sufficient condition for $\lambda$-convexity (c.f. \cite[Proposition 2.7]{CraigNonconvex}) is that for all geodesics $\mu_\alpha$ with $\mu_0,\mu_1 \in D(\F^m_\e)$, we have that $\alpha \mapsto \F^m_\e(\mu_\alpha)$ is differentiable for $\alpha \in [0,1]$  and
%\[ \F^m_\e(\mu_1) - \F^m_\e(\mu_0) - \left. \frac{d}{d \alpha}\F^m_\e(\mu_\alpha) \right|_{\alpha = 0} \geq \frac{\lambda}{2} W_2^2(\mu_0,\mu_1) . \]
%\kcomment{I will write the proof in the case when there exists an  optimal transport map $\bt_{\mu_0}^{\mu_1}(x)$ from $\mu_0$ to $\mu_1$. The generalization to optimal transport plans and generalized geodesics is straightforward.} First, note that for $m \geq 2$ and any $ \alpha  \in [0,1]$,
%\[ \F^m_\e(\mu_\alpha) = \int (\varphi_\e*\mu_\alpha)^{m-1} d \mu_\alpha \leq \|\varphi_\e \|_\infty^{m-1} , \]
%so $\mu_\alpha \in D(\F^m_\e)$ for all $\alpha \in [0,1]$. Furthermore, for $\beta \in [0,1]$, the curve $\hat{\mu}_\beta = \mu_{(1-\beta)\alpha+\beta}$ is a geodesic from $\mu_\alpha$ to $\mu_1$, and noting that $\mu_{(1-\beta)\alpha+\beta} =  ((1-\beta) \id + \beta \bt_{\mu_\alpha}^{\mu_1}) \# \mu_\alpha = ((\id + \beta (\bt_{\mu_\alpha}^{\mu_1}-\id)) \# \mu_\alpha$ for $\bt_{\mu_\alpha}^{\mu_1}-\id \in L^2(\mu_\alpha)$, Lemma \ref{diff lem} ensures that 
%\[ \left. \frac{d}{d \beta}  \F_\e^m(\hat{\mu}_\beta) \right|_{\beta = 0} = \frac{d}{d \alpha} \F_\e^m(\mu_\alpha)\] exists for any $\alpha \in [0,1]$. In particular, the derivative exists at $\alpha = 0$ and
%\[ \left. \frac{d}{d \alpha } \F^m_\e(\mu_\alpha) \right|_{\alpha = 0}= \iint  \grad \varphi_\e(x-y) \cdot ((\bt(x)-x)-(\bt(y)-y))  (\varphi_\e*\mu_0)(x)^{m-2} d \mu_0(y) d \mu_0(x). \]
%
%By inequality (\ref{tangent line convex}),
%\begin{align*}
% &\F^m_\e(\mu_1) - \F^m_\e(\mu_0) - \left. \frac{d}{d \alpha}\F^m_\e(\mu_\alpha) \right|_{\alpha = 0} \\
% & \geq
% \iint \left[ \varphi_\e(\bt(x)-\bt(y)) - \varphi_\e(x-y) - \grad \varphi_\e(x-y) \cdot ((\bt(x)-x)-(\bt(y)-y)) \right]  (\varphi_\e*\mu_0)(x)^{m-2} d \mu_0(y)  d \mu_0(x)\\
%&\geq -\frac{\|D^2 \varphi_\e\|_\infty}{2} \iint((\bt(x)-x)-(\bt(y)-y))^2   (\varphi_\e*\mu_0)(x)^{m-2} d \mu_0(y)  d \mu_0(x) \\
%&\geq -\frac{\|D^2 \varphi_\e\|_\infty \|\varphi_\e\|_\infty^{m-2}}{2}   \int((\bt(x)-x)-(\bt(y)-y))^2 d \mu_0(y) d \mu_0(x) \\
%&\geq -\|D^2 \varphi_\e\|_\infty \|\varphi_\e\|_\infty^{m-2} \int |\bt(x)-x|^2 + |\bt(y)-y|^2 d \mu_0(y)  d \mu_0(x) \\
%&= -2\|D^2 \varphi_\e\|_\infty \|\varphi_\e\|_\infty^{m-2} W_2^2(\mu_0,\mu_1) .
% \end{align*}
% This gives the result.
%\end{proof}


\begin{remark} \kcomment{Need to adapt this comment to new version of lemma.}
Note that if $\lambda = 0$ in Proposition \ref{thm:conv}, then $\F$ is convex on all of $\P_2(\R^d)$. Also, if $F'\in L^\infty(\R)$, then $\lambda_R$ does not depend on $R$ and we get convexity of $\F$ on all of $\P_2(\R^d)$ as well. The latter case happens for instance when $F(x)=x$, which corresponds to the square diffusion.
\end{remark}



\section{$\Gamma$-convergence of regularized entropies}

\begin{thm} \label{Gamma convergence theorem2}
For all $m \geq 1$, the regularized energies $\F^m_\e$ $\Gamma$-converge to $\F^m$. In particular,
\begin{enumerate}[(a)]
\item for all $\mu_\e, \mu \in \P_2(\Rd)$ satisfying $\mu_\e \wsto \mu$, we have $\liminf_{\e \to 0 } \F^m_\e(\mu_\e) \geq \F^m(\mu)$; \label{liminf condition 2}
\item for all $\mu \in \P_2(\Rd)$, we have $\limsup_{\e \to 0} \F^m_\e(\mu) \leq \F^m(\mu)$. \label{limsup condition 2}
\end{enumerate}
\end{thm}

\begin{remark}[Gamma convergence for $F$ concave]
The same proof shows the $\Gamma$-convergence of the regularized internal energies $\F_\e$ whenever $F(x)$ is concave \kcomment{lower semicontinuous, other assumptions...}.
\end{remark}

\begin{proof}
We begin by showing the result for $1 \leq m \leq 2$, in which case $F(s)$ is concave. 
We first show part (\ref{liminf condition 2}). By Proposition \ref{relative sizes lemma},
\[ \F^m_\e(\mu_\e) \geq \F^m(\zeta_\e* \mu_\e) . \]
By Proposition \ref{narrow convergence mollified sequence},  $ \mu_\e \rightharpoonup \mu$ implies $\zeta_\e* \mu_\e\rightharpoonup \mu$. Therefore,  by the lower semicontinuity of $\F$ with respect to narrow convergence,
\[ \liminf_{\e \to 0} \F^m_\e(\mu_\e) \geq  \liminf_{\e \to 0}  \F^m(\zeta_\e* \mu_\e) \geq \F^m(\mu) , \]
which gives the result.
We now turn to part (\ref{limsup condition 2}). Again, by Proposition \ref{relative sizes lemma},
\[ \F(\mu) + C_\e \geq \F_\e(\mu) , \]
where $C_\e \to 0$ as $\e \to 0$.
Therefore, for any $\mu \in \P_2(\Rd)$,  $\limsup_{\e \to 0} \F^m_\e(\mu) \leq \F^m(\mu)$.

We now consider the case when $m>2$. Part (\ref{limsup condition 2}) follows quickly: by Proposition \ref{relative sizes lemma}, Young's convolution inequality, and the fact that $ \|\zeta_\e\|_1 = 1$,
\[ \F^m_\e(\mu) \leq \F^m(\zeta_\e *\mu) = \frac{1}{m-1} \|\zeta_\e*\mu\|_m^m \leq \frac{1}{m-1} ( \|\zeta_\e\|_1 \|\mu\|_m)^m =\frac{1}{m-1}  \|\mu\|_m^m   = \F^m(\mu).\]
Taking $\limsup_{\e \to 0}$ then gives the result.

We now prove part (\ref{liminf condition 2}). Without loss of generality, we may suppose that $\liminf_{\e \to 0} \mathcal{F}^m_\e(\mu_\e)$ is finite. Furthermore, there exists a subsequence $\e_n \to 0$ so that $\lim_{n \to + \infty} \mathcal{F}_{\e_n}^m(\mu_{\e_n}) = \liminf_{\e \to 0} \mathcal{F}^m_\e(\mu_\e)$. In particular, there exists $C>0$ for which $\F^m_{\e_n}(\mu_{\e_n})  < C$ for all $n \in \mathbb{N}$.

By Jensen's inequality for the convex function $x \mapsto x^{m-1}$ and the fact that $\zeta_\e * \zeta_\e = \varphi_\e$,
\[ \F^m_\e(\mu_\e)= \frac{1}{m-1} \int (\varphi_\e * \mu_\e)^{m-1} d \mu_\e \geq \frac{1}{m-1} \left( \int \varphi_\e * \mu_\e d \mu_\e \right)^{m-1} = \frac{1}{m-1} \left( \int |\zeta_\e*\mu_\e|^2 \right)^{m-1} .\]
Thus, since $\F^m_{\e_n}(\mu_{\e_n})  < C$, we have $\|\zeta_{\e_n}*\mu_{\e_n}\|_2< C':= (C(m-1))^{1/2(m-1)}$ for all $n \in \mathbb{N}$.

We now use this bound on the $L^2(\Rd)$ norm of $\zeta_{\e_n}*\mu_{\e_n}$ to deduce a stronger notion of convergence of $\zeta_{\e_n}*\mu_{\e_n}$ to $\mu$. First, since $\mu_{\e_n} \wsto \mu$,  Proposition \ref{narrow convergence mollified sequence} ensures that $\zeta_{\e_n}*\mu_{\e_n} \wsto \mu_{\e_n}$.
Since $\|\cdot \|_2$ is lower semicontinuous with respect to convergence in the weak-* topology of $\P(\Rd)$ \textcolor{blue}{cite McCann}, we have
\[ C' \geq \liminf_{n \to +\infty} \|\zeta_{\e_n}*\mu_{\e_n}\|_2 \geq \|\mu\|_2 ,\]
so $\mu \in L^2(\Rd)$. Furthermore, up to another subsequence, we may assume that $\zeta_{\e_n}*\mu_{\e_n}$ converges weakly in $L^2(\Rd)$ to some $w \in L^2(\Rd)$. Since $\zeta_{\e_n}*\mu_{\e_n} \wsto \mu$, for all $f \in C^\infty_c(\Rd)$,
\[ \int f w = \lim_{n \to +\infty} \int f \zeta_{\e_n}*\mu_{\e_n} = \int f \mu ,\]
so $\zeta_{\e_n}*\mu_{\e_n} \stackrel{L^2}{\rightharpoonup} \mu$. By the Banach-Saks theorem \textcolor{blue}{cite}, up to taking a further subsequence of $\zeta_{\e_n}*\mu_{\e_n}$, the Ces\`aro mean $v_k := \frac{1}{k} \sum_{n=1}^k \zeta_{\e_n}*\mu_{\e_n}$ converges to $\mu$ strongly in $L^2(\Rd)$. Finally, for any $f \in C^\infty_c(\Rd)$, this ensures
 \[ \left| \int f (v_k)^2 - \int f \mu^2 \right| \leq \int |f| |v_k-\mu||v_k +\mu| \leq  \|f\|_\infty  \|v_k -\mu\|_{L^2(\Rd)} \|v_k + \mu\|_{L^2(\Rd)},\]
 so 
 \begin{align} \label{dist conv of square} 
 \lim_{k \to +\infty} \int f (v_k)^2 = \int f \mu^2 .
 \end{align}
 
 We now use this stronger notion convergence to conclude our proof of part (\ref{liminf condition 2}). Since $m>2$ and 
 \[  \| \varphi_{\e_n} * \mu_{\e_n} \|_{L^{m-1}(d \mu_{\e_n})}^{m-1} = (m-1) \F^m_{\e_n}(\mu_{\e_n})  < C \text{ for all } n \in \mathbb{N}, \]
by part (\ref{weakcpt}) of Proposition \ref{AGSthm}, up to another subsequence,  there exists $w \in L^1(d\mu)$ so that for all $f \in C^\infty_c(\Rd)$,
 \begin{align} \lim_{n \to +\infty} \int f (\varphi_{\e_n} * \mu_{\e_n}) d \mu_{\e_n} = \int f w d \mu . \label{weak conv prob}
 \end{align}
 Furthermore, recalling the definition of $\mathcal{F}^m_\e(\mu_\e)$ and applying part (ii) of \cite[Theorem 5.4.4]{AGS},
 \[ \liminf_{\e \to 0} \mathcal{F}^m_\e(\mu_\e) = \lim_{n \to +\infty} \mathcal{F}_{\e_n}(\mu_{\e_n}) = \lim_{n \to +\infty} \frac{1}{m-1} \int (\varphi_{\e_n}*\mu_{\e_n})^{m-1} d \mu_n  \geq \frac{1}{m-1} \int w^{m-1} d\mu . \]
 Therefore, to finish the proof, it suffices to show that $w(x) \geq \mu(x)$ for $\mu-$almost every $x \in \Rd$.

By Lemma \ref{move mollifier prop} and the fact that $\zeta_{\e_n} *\zeta_{\e_n} = \varphi_{\e_n}$, there exists $C_\zeta >0$ depending on the mollifier $\zeta$ so that for all $f \in C^\infty_c(\Rd)$,
\begin{align} \left|\int f (\varphi_{\e_n} * \mu_{\e_n}) d \mu_{\e_n}  - \int f (\zeta_{\e_n} * \mu_{\e_n})^2 \right| &= \left|\int \zeta_{\e_n} *(f \mu_{\e_n}) \zeta_{\e_n} *\mu_{\e_n} - \int f  (\zeta_{\e_n} * \mu_{\e_n})( \zeta_{\e_n} * \mu_{\e_n}) \right| \\
&\leq \  C_\zeta \epsilon_n \|\grad f \|_\infty  \|\zeta_{\e_n} * \mu_{\e_n} \|_{L^2(\Rd)}^2 .  
\end{align}
Combining this with equation (\ref{weak conv prob}), we obtain
\begin{align} \lim_{n \to +\infty} \int f (\zeta_{\e_n} *\mu_{\e_n})^2 = \int f w d \mu . \label{first zeta mu convergence}
\end{align}
Finally, using equation (\ref{dist conv of square}) and the definition of $v_k$ as a sequence of convex combinations of $\zeta_{\e_n} *\mu_{\e_n}$, for all $f \in C^\infty_c(\Rd)$ with $f \geq 0$,
\[ \int f \mu^2 = \lim_{k \to +\infty} \int f(v_k)^2  = \lim_{k \to +\infty} \int f \left( \frac{1}{k}\sum_{n=1}^k \zeta_{\e_n}*\mu_{\e_n} \right)^2 \leq  \lim_{k \to +\infty} \frac{1}{k} \sum_{n=1}^k  \int f \left( \zeta_{\e_n}*\mu_{\e_n} \right)^2 . \]
Since the limit in equation (\ref{first zeta mu convergence}) exists, it coincides with its Ces\`aro sum on the right hand side of the above equation. Thus, for all $f \in C^\infty_c(\Rd)$ with $f \geq 0$,
\[ \int f \mu^2 \leq \int f w d \mu . \]
This gives $w(x) \geq \mu(x)$ for $\mu-$almost every $x \in \Rd$, which completes the proof.
\end{proof}

By combining our regularized internal energies with a confining drift or interaction potential, we can use the above $\Gamma$-convergence result to conclude that minimizers converge to minimizers. In particular, we consider the following energies.
\begin{defi} \label{confined energies}
Suppose $V: \Rd \to \mathbb{R} \cup \{ +\infty \}$ is lower semicontinuous function that is bounded below with compact sublevels. Suppose $W: [0, +\infty) \to \R \cup \{+\infty\}$ is lower semicontinuous, satisfies $\lim_{r \to +\infty} W(r) = +\infty$ , and the function $x \mapsto W(|x|)$ is locally integrable on $\Rd$. \kcomment{State hypotheses on $\mathcal{F}_\e$.} Then, we define
\begin{align*} \mathcal{V}_\e(\mu) &:=  \int V d \mu  + \mathcal{F}_\e(\mu)  ,  && \mathcal{V}(\mu) :=  \int V d \mu  + \mathcal{F}(\mu)  ; \\
\mathcal{W}_\e(\mu) &:= \int W*\mu \  d \mu + \mathcal{F}_\e(\mu)  , &&\mathcal{W}(\mu) := \int W*\mu \  d \mu  + \mathcal{F}(\mu)  .
\end{align*}
\end{defi}

\begin{remark}[proper, lower semicontinuous, coercive] \label{lsc remark}
\kcomment{Our assumptions on $V$ and $W$ ensure that the energies $\mathcal{V}_\e$ and $\mathcal{W}_\e$ are proper, lower semicontinuous, and coercive for all $\e >0$. \cite[Lemma 5.1.7]{AGS}, \cite[Lemma 2.2]{SimioneSlepcevTopaloglu}, and Proposition \ref{lower semicontinuity}}
\end{remark}

\begin{remark}[tightness of sublevels] \label{sublevel remark}
Our assumptions on $V$ ensure that for all $C \geq 0 $, the set $\{ \mu \in \P(\Rd) : \int V d \mu \leq C \}$ is tight \cite[Remark 5.1.5]{AGS}. Likewise, our assumptions on $W$ ensure that for all $C \geq 0$, the set $\{ \mu \in \P(\Rd) : \int W*\mu d \mu \leq C \}$ is tight up to translations \cite[Theorem 3.1]{SimioneSlepcevTopaloglu}.
\kcomment{It would be interesting to weaken the conditions on $V$ or $W$, but that may be beyond the scope of the present work :).}
\end{remark}

Since the regularized internal energies $\F_\e(\mu)$ are nonnegative for $m > 1$, the tightness of sublevels described in Remark \ref{sublevel remark} allows us to quickly conclude that minimizers of $ \mathcal{V}_\e(\mu) $ and $\mathcal{W}_\e(\mu)$ exist.

\begin{prop}
Given $\mathcal{V}_\e$ and $\mathcal{W}_\e$ as in Definition \ref{confined energies},  minimzers of $\mathcal{V}_\e$  and $\mathcal{W}_\e$ over $\P(\Rd)$ exist for all  $\e >0$. \textcolor{red}{I have only proved for $m >1$, where $\F_\e$ is nonnegative. In the case $m=1$, we may want to require that $V$ and $W$ have quadratic growth at infinity to control the second moments of the minimizing sequence.}
\end{prop}


\begin{proof}
Combining Remark \ref{sublevel remark} with the fact that $\F_\e(\mu) \geq 0$ ensures that any minimizing sequence of $\mathcal{V}_\e(\mu)$ has a subsequence that converges in the weak-* topology of $\P(\Rd)$ and any minimizing sequence of $\mathcal{W}_\e(\mu)$ has a subsequence that, up to translation, converges in the weak-* topology. By Remark \ref{lsc remark}, $\mathcal{V}_\e$ and $\mathcal{W}_\e$ are also lower semicontinuous. Thus, any minimizing sequence of $\mathcal{V}_\e$ has a convergent subsequence that converges to a minimizer of $\mathcal{V}_\e$. Similarly, since $\mathcal{W}_\e$ is translation invariant, any minimizing sequence of $\mathcal{W}_\e$ has a subsequence which, up to translation, converges to a minimizer of $\mathcal{W}_\e$. Therefore, we conclude that minimizers of $\mathcal{V}_\e$ and $\mathcal{W}_\e$ over $\P(\Rd)$ exist.
\end{proof}

Finally, we conclude that minimizers of $\mathcal{V}_\e$ and $\mathcal{W}_\e$ converge to minimizers of $\mathcal{V}$ and $\mathcal{W}$.

\begin{thm}[minimizers converge to minimizers] \label{minimizers converge theorem}
Consider a sequence $\{ \mu_\e\}_{\e >0}$. If $ \mu_\e$ is a minimizer of $\mathcal{V}_\e$, then up to a subsequence, $\mu_\e \wsto \mu$, where $\mu$ is a minimizers of $\mathcal{V}$. Likewise, if $\mu_\e$ is a minimizer of $\mathcal{W}_\e$, then up to a subsequence and translation, $\mu_\e \wsto \mu$, where $\mu$ is a minimizers of $\mathcal{W}$. \textcolor{red}{I have only proved for $m>1$, when $\F_\e$ is nonnegative.}
\end{thm}
 
 The proof of Theorem \ref{minimizers converge theorem} is classical. We include it for completeness.

\begin{proof}
We will prove the result for $\mathcal{V}_\e$. The argument for $\mathcal{W}_\e$ is analogous. Since $\mu_\e$ is a minimizer of $\mathcal{V}_\e$, for any $\nu \in \P(\Rd)$, $\mathcal{V}_\e(\mu_\e) \leq \mathcal{V}_\e(\nu)$. Taking the $\liminf$ of the left hand side and the $\limsup$ of the right hand side, Theorem \ref{Gamma convergence theorem2}(\ref{limsup condition 2}) ensures that 
\begin{align} \label{minimizers ineq}
 \liminf_{\e \to 0} \mathcal{V}_\e(\mu_\e) \leq \limsup_{\e \to 0} \mathcal{V}_\e(\nu) \leq \mathcal{V}(\nu) . 
 \end{align}
By Remark \ref{lsc remark}, $\mathcal{V}$ is proper, so there exists $\nu \in \P(\Rd)$ so that the right hand side is finite. Then, up to a subsequence, we may assume that $ \mathcal{V}_\e(\mu_\e)$ is uniformly bounded. Since $\F_\e(\mu) \geq 0$, this implies that $\int V d \mu_\e$ is uniformly bounded, so by Remark \ref{sublevel remark}, $\mu_\e$ has a subsequence converging to some $\mu \in \P(\Rd)$. By Theorem \ref{Gamma convergence theorem2}(\ref{liminf condition 2}) and inequality (\ref{minimizers ineq}), we obtain
\[ \mathcal{V}(\mu) \leq  \liminf_{\e \to 0} \mathcal{V}_\e(\mu_\e) \leq \mathcal{V}(\nu) ,
\]
for all $\nu \in \P(\Rd)$. Therefore, up to a subsequence, $\mu_\e \wsto \mu$, where $\mu$ is a minimizers of $\mathcal{V}$.
\end{proof}


\section{Gradient flows of regularized internal energies}

%\begin{prop} \label{Lipschitz estimates}
%For all $\rho \in \P(\Rd)$, $m \geq 1$, and  $\e >0$, the velocity field given by
%\[ v(x) =  \grad \varphi_\e* \left((\varphi_\e*\rho)^{m-2} \rho \right) + (\varphi_\e*\rho)^{m-2} (\grad \varphi_\e * \rho). \]
%satisfies $\|\grad v \|_\infty \leq C_{m, \e}$ and $|v(x)| \leq A_{m,\e} \textcolor{red}{+ B_{m,\e}|x|}$ for all $x \in \Rd$.
%\end{prop}
%\begin{proof}
%\kcomment{For $m>1$, these estimates seem standard. I need to think a bit more about the $m=1$ case. We may only be able to show $\grad v$ is locally bounded, but that should still be enough.}
%\end{proof}
%
%\begin{prop}
%For any initial data $\rho_0 \in \P(\Rd)$ \textcolor{red}{might need to restrict to $\P_2(\Rd)$ to ensure AGS 8.1.2. }and $T>0$, there exists a unique curve in the space of probability measures $\rho: [0,T] \to \P(\Rd)$ so that $\rho(t)$ is narrowly continuous in time, $\rho(0) = \rho_0$, and $\rho(t)$ is a weak solution of
%\begin{align*}
%&\dfrac{d}{dt} \rho + \grad \cdot( v \rho) = 0, \  \quad \  v =  \grad \varphi_\e* \left((\varphi_\e*\rho)^{m-2} \rho \right) + (\varphi_\e*\rho)^{m-2} (\grad \varphi_\e * \rho) ,
%\end{align*}
%in the duality with $C^\infty_c(\Rd \times (0,T))$.
%\end{prop}
%\begin{proof}
%\kcomment{This is a consequence of Proposition \ref{Lipschitz estimates} and \cite[Lemma 8.1.6, Proposition 8.1.7, Proposition 8.1.8]{AGS}.}
%\end{proof}

\begin{prop}
\textcolor{red}{For any $m\geq 2$ and $\rho_0 \in \P_2(\Rd)$, there exists a unique gradient flow of $\F_\e^m$ with initial data $\rho_0$.}
\end{prop}

\begin{proof}
\textcolor{red}{AGS Theorem 11.1.4.}
\end{proof}

\begin{prop}
\textcolor{red}{$\rho(x,t)$ is a weak solutions of the continuity equation with $v = \grad \frac{\partial \F_\e^m}{\partial \rho}$ if and only if $\rho(x,t)$ is a gradient flow of $\F_\e^m$.}
\end{prop}

\begin{proof}
\textcolor{red}{This is a consequence of the characterization of the subdifferential}
\end{proof}

\begin{cor} \label{particles well posed}
Suppose $I \subseteq \N$ and $X_i(0) \in \Rd$, $m_i \geq 0$ for all $i \in I$. Then the ODEs
\begin{align} \label{ODEsystem}
\partial_t X_i(t) =- \grad \frac{\partial E_\e}{\partial \mu} (\Sigma_j \delta_{X_j(t)} m_j ) 
\end{align}
with initial data $(X_i(0))_{i \in I}$ are well-posed, and $\mu_t = \sum_{i \in I} \delta_{X_i(t)} m_i$ is a gradient flow of $\F_\e^m$.
\end{cor}


\begin{remark}
Corollary \ref{particles well posed} does not apply to the unregularized entropy as solutions with Dirac mass initial data instantly become absolutely continuous with respect to Lebesgue measure for all $t>0$.
\end{remark}

\begin{proof}[Proof of Corollary \ref{particles well posed}]
\textcolor{red}{This proof needs to be fixed to reflect the new statement of the previous corollary}
Suppose $X_i(t)$ solves (\ref{ODEsystem}) with initial data $X_i(0)$. For any test function $\varphi(x,t) \in C^\infty_c(\Rd \times (0,T))$, the fundamental theorem of Calculus ensures \begin{align*}
\int_0^T \grad \varphi(X_i(t),t) \partial_t X_i(t) + \partial_t \varphi( X_i(t),t) dt = -\varphi(X_i(0),0).
\end{align*}
Combining this with (\ref{ODEsystem}), we obtain
\begin{align*}
 \int_0^{T} \partial_t \varphi(X_i(t),t) dt  + \varphi(X_i(0),0) - \int_0^{T} \grad \varphi(X_i(t),t) \grad \frac{\partial E_\e}{\partial \mu} (\Sigma_j \delta_{X_j(t)} m_j)  dt = 0
\end{align*}
Multiplying both sides by $m_i$, summing over $i$, and taking $\mu(t) = \sum_i \delta_{X_i(t)} m_i$, we obtain
\begin{align*}
\int_0^{T} \partial_t \varphi(x,t)\,d \mu_t(x) dt + \int_\Rd \varphi(x,0)\,d \mu_0(x) +\int_0^{T} \int_{\Rd} \grad \varphi(x,t) v_t\,d \mu_t(x) dt  =0.
\end{align*}
Therefore, $\mu(t) = \sum_i \delta_{X_i(t)} \mu_i$ is a gradient flow of $\F_\e^m$.
\end{proof}

\section{$\Gamma$-convergence of gradient flows}

We now prove the $\Gamma$-convergence of the gradient flows for regularized R\'enyi entropies. Let
\[ \F^m(\mu) = \begin{cases} \frac{1}{m-1} \int \mu^m & \text{ if } \mu \ll \mathcal{L}^d , \\ +\infty & \text{ otherwise,} \end{cases} \qquad \quad  \F^m_\e(\mu) = \int (\varphi_\e *\mu)^{m-1} d \mu . \]
We will show the convergence of the gradient flows by using the following scheme introduced by Serfaty\cite[Theorem 2]{Serfaty}.
\begin{thm}[{c.f. \cite[Theorem 2]{Serfaty}}]\label{thm:serfaty}
Suppose that $\mu_\e \in AC^2([0,T],\P_2(\R^d))$ is a gradient flow of $\F_\e$ so that for some $\mu \in AC^2([0,T],\P_2(\R^d))$,
\begin{align} \label{well prepared}  \mu_\e(t) \wto \mu(t) \text{ narrowly for }t \in [0,T] \quad \text{ and } \quad \lim_{\e \to 0} \F^m_\e(\mu_\e(0)) = \F^m(\mu(0)) .
\end{align}
If the following criteria hold for all $t \in [0,T]$,
\begin{enumerate}
	\item \label{cond:md} $\displaystyle \liminf_{\e\to 0} \int_0^t |\mu_\e'|(s)^2 \,d s \geq \int_0^t|\mu'|(s)^2\,d s$,\\
	\item \label{cond:liminf} $\displaystyle \liminf_{\e\to0} \F^m_\e(\mu_\e(t)) \geq \displaystyle \F^m(\mu(t))$,\\
	\item \label{cond:slopes} $\displaystyle \liminf_{\e\to 0} |\partial \F^m_\e|(\mu_\e(t)) \geq |\partial \F^m|(\mu(t))$,
\end{enumerate}
then equality holds in (1-3), and $\mu(t)$ is the gradient flow of $\F^m$ with initial data $\mu(0)$.
\end{thm}


\begin{thm}
For $m \geq 2$, suppose that $\mu_\e \in AC^2([0,T],\P_2(\R^d))$ is a gradient flow of $\F_\e$ so that for some $\mu \in AC^2([0,T],\P_2(\R^d))$,
\begin{align}   \mu_\e(t) \wto \mu(t) \text{ narrowly for }t \in [0,T] \quad \text{ and } \quad
 \lim_{\e \to 0} \F^m_\e(\mu_\e(0)) = \F^m(\mu(0)) .
\end{align}
Furthermore, assume the following hold for all $t \in [0,T]$,
\begin{align} \label{extra assumptions a}
 &\zeta_\e*\mu_\e(t) \xrightarrow{L^m(\Rd)} \mu(t) , \\
 &\sup_{\e >0} \int |x|^{m-1}d \mu_\e(t) <+\infty ,  \label{extra assumptions b}\\
 &\sup_{\e >0} \iint  \zeta_\e(x-y) \left| (\nabla \zeta_\e * p_\e)(x)  + (\nabla \zeta_\e * \mu_\e) (x) (\varphi_\e*\mu_\e)(y)^{m-2} \right|d\mu_\e(y) dx < +\infty , \label{extra assumptions c}
\end{align}
where $p_\e = (\varphi_\e *\mu_\e)^{m-2} \mu_\e$. Then $\mu(t)$ is the gradient flow of $\mathcal{F}^m$ with initial data $\mu(0)$, 
\end{thm}

\begin{remark}
{\color{Aquamarine}  Explain why we need additional assumptions, and explain why they are reasonable. Refer to L-MG, though ours are slightly weaker.} {\color{Aquamarine} Note that we are NOT using finiteness of the subdifferentially -- morally speaking, this is what *should* be giving us the stronger notion of convergence that instead we assume -- but the absolute value signs are in the wrong place }

{\color{Aquamarine} A sufficient condition for (\ref{extra assumptions c}) is...
\begin{enumerate}[(i)]
\item $\|\zeta_\e*\mu_\e(t) \|_{W^{1,m}} < C$, \label{H1i}
\item $\|\zeta_\e*p_\e(t) \|_{W^{1,m'}} < C $, where $p_\e = (\varphi_\e *\mu_\e)^{m-2} \mu_\e$ and $\frac{1}{m} + \frac{1}{m'} = 1$.
\end{enumerate}
 Explain why hypotheses are reasonable theoretically. (The first is a constraint on the density, while the second is a constraint on the ``pressure''.) Refer to numerics section for why hypotheses are reasonable numerically. Explain where hypotheses are needed in our proof. 

Ultimate moral: we need SOMETHING uniform in $\e$. We couldn't prove anything in general, so these were the weakest hypotheses we could think of that could be verified numerically. In the $m=2$ case, they reduce to something you can prove (which is similar to L-MG). On the other hand, unlike the way L-MG framed them, ours can be verified numerically and are overall closer to the numerical scheme.}
\end{remark}

\begin{proof}
It suffices to verify items (\ref{cond:md}), (\ref{cond:liminf}), and (\ref{cond:slopes}) from Theorem \ref{thm:serfaty}. Throughout the proof, we will use Hypothesis \ref{mollifierAssumption}, which ensures $\varphi_\e = \zeta_\e*\zeta_e$, and Lemma \ref{convolutionlemma}.

Item (\ref{cond:md}) follows by the same argument as in \cite[Theorem 5.6]{CraigTopaloglu}, and item (\ref{cond:liminf}) follows by Theorem \ref{Gamma convergence theorem2}. In fact, due to the additional assumption (\ref{extra assumptions a}), we may prove something stronger than item (\ref{cond:liminf}), which we will use in what follows. By Proposition \ref{relative sizes lemma},
$\F_\e^m(\mu_\e) \leq \frac{1}{m-1} \|\zeta_\e*\mu_\e\|_m^m$, so applying assumption (\ref{extra assumptions a}), we obtain $\limsup_{\e \to 0} \F_\e^m(\mu_\e) \leq \F^m(\mu)$.
Combining this with (\ref{cond:liminf}) gives 
\begin{align} \label{energyconv}
\lim_{\e \to 0} \F^m_\e(\mu_\e) = \F^m(\mu).
\end{align}

We now proceed to item (\ref{cond:slopes}). Without loss of generality, we may assume that $\liminf_{\e \to 0}\F^m_\e(\mu_\e)$ and $\liminf_{\e \to 0} |\partial \F^m_\e(\mu_\e)|$ are finite and, up to taking further subsequences, $\F^m_\e(\mu_\e)$ and $|\partial \F^m_\e(\mu_\e)|$ are uniformly bounded in $\epsilon$. This also ensures that $|\partial \F^m(\mu)|$ is finite so, by {\color{Aquamarine} cite AGS proposition}, this implies $\mu^{m-1} \in W^{1,1}(\Rd)$ and 
\begin{align*}
|\partial F^m|(\mu) = \frac{m}{m-1} \| \grad (\mu^{m-1} ) \|_{L^2(d \mu)}
\end{align*}
Likewise, by Proposition \ref{subdiffchar},
\begin{align} \label{vepsdef}
|\partial \F^m_\e|(\mu) = \left\|v_\e \right\|_{L^2(d \mu_\e)}, \text{ where } v_\e = \grad \varphi_\e* \left((\varphi_\e*\mu_\e)^{m-2} \mu_\e \right) + (\varphi_\e* \mu_\e)^{m-2} (\grad \varphi_\e * \mu_\e).
\end{align}
Consequently, to prove item (\ref{cond:slopes}), we must show
\[ \liminf_{\e \to 0}  \left\| v_\e \right\|_{L^2(d \mu_\e)} \geq \frac{m}{m-1} \| \grad (\mu^{m-1} ) \|_{L^2(d \mu)} . \]
Finally, by Proposition \ref{AGSthm}, part (\ref{weaklsc}), it is sufficient to show that $v_\e$ weakly converges to $\frac{m}{m-1} \grad (\mu^{m-1} )$. In particular, we must show that for all $f \in C^\infty_c(\Rd)$, 
\begin{align} \label{GFgoal1}
\lim_{\e \to 0} \int f v_\e d \mu_\e = \frac{m}{m-1} \int f \grad (\mu^{m-1} ) d \mu = \int f \grad (\mu^m).
\end{align}

We begin by using the expression for $v_\e$ in equation (\ref{vepsdef}) to rewrite the left hand side of (\ref{GFgoal1}). Abbreviating $p_\e = (\varphi_\e *\mu_\e)^{m-2} \mu_\e$,
\begin{align*}
 \int f v_\e d \mu_\e &= \int f \left( (\grad \varphi_\e* p_\e) + (\varphi_\e* \mu_\e)^{m-2} (\grad \varphi_\e * \mu_\e) \right) d \mu_\e = \int  (\zeta_\e *(f \mu_\e)) (\grad\zeta_\e*p_\e) + (\zeta_\e*(f p_\e)) (\grad \zeta_\e*\mu_\e)
\end{align*}
Next, we show that we may ``move $f$ out the convolutions'' as $\e \to 0$. In particular,
\begin{align*}
&\left| \int (\zeta_\e *(f \mu_\e)) (\grad\zeta_\e*p_\e) + (\zeta_\e*(f p_\e)) (\grad \zeta_\e*\mu_\e) - \int f( \zeta_\e * \mu_\e) (\grad\zeta_\e*p_\e) + f(\zeta_\e* p_\e) (\grad \zeta_\e*\mu_\e) \right| \\
&\quad = \left| \iint \zeta_\e(x-y)[f(y)-f(x)]  \left[ (\grad \zeta_\e*p_\e)(x) + (\grad \zeta_\e*\mu_e)(x) (\varphi_\e*\mu_\e)(y)^{m-2} \right] d \mu_\e(y) dx \right| \\
&\quad \leq \e \|\grad f\|_\infty \iint \zeta_\e(x-y) \left| (\grad \zeta_\e*p_\e)(x) + (\grad \zeta_\e*\mu_\e)(x)(\varphi_\e*\mu_\e)(y)^{m-2} \right| d \mu_\e(y) dx 
\end{align*}
where the double integral is bounded uniformly in $\e$ by (\ref{extra assumptions c}). {\color{Aquamarine}  {explain why this works even when $\zeta_\e$ isn't compactly supported}}
Consequently,
\begin{align*}
\lim_{\e \to 0} \int f v_\e d \mu_\e &= \lim_{\e \to 0}\int f( \zeta_\e * \mu_\e) (\grad\zeta_\e*p_\e) + f(\zeta_\e* p_\e) (\grad \zeta_\e*\mu_\e) \\
& = - \lim_{\e \to 0}  \int \grad f ( \zeta_\e * \mu_\e) (\zeta_\e*p_\e) =- \lim_{\e \to 0}  \int \zeta_\e*(\grad f ( \zeta_\e * \mu_\e)) p_\e
\end{align*}
We again ``move $\grad f$ out of the convolution''. By Proposition \ref{move mollifier prop},
\begin{align*}
\left| \int \zeta_\e*(\grad f ( \zeta_\e * \mu_\e)) p_\e - \int \grad f (\zeta_\e*( ( \zeta_\e * \mu_\e))) p_\e \right| & \leq \e C_\zeta \|\grad f \|_\infty  \int (\varphi_\e*\mu_\e)^{m-1} d \mu_\e  \\
&   = \e C_\zeta \|\grad f \|_\infty \F^m_\e(\mu_\e).
\end{align*}
Since $\F^m_\e(\mu_\e)$ is uniformly bounded in $\epsilon$, 
\begin{align} \label{almostdone}
\lim_{\e \to 0} \int f v_\e d \mu_\e = - \lim_{\e \to 0} \int \grad f (\varphi_\e*\mu_\e) p_\e =- \lim_{\e \to 0} \int \grad f (\varphi_\e*\mu_\e)^{m-1} d \mu_\e.
\end{align}

To conclude the proof, we aim to apply Proposition \ref{AGSthm}, part (\ref{strongcty}), and we begin by verifying the hypotheses of this proposition. First, note that since $\zeta_\e*\mu_\e \to \mu$ in $L^m(\Rd)$ for $m \geq 2$ and  $\|\zeta_\e*\mu_\e \|_{L^1(\Rd)} = \|\mu\|_{L^1(\Rd)} = 1$, {\color{Aquamarine}  {fix exponents in below formula!}}
\[ \|\zeta_\e*\mu_\e - \mu\|_{L^2(\Rd)} \leq \|\zeta_\e*\mu_\e - \mu\|_{L^m(\Rd)}  \|\zeta_\e*\mu_\e - \mu\|_{L^1(\Rd)}  \leq 2\|\zeta_\e*\mu_\e - \mu\|_{L^m(\Rd)} \to 0 .\]
Let $w_\e = \varphi_\e*\mu_\e$. Then $\int w_\e d \mu_\e = \int (\zeta_\e*\mu_\e)^2$, so $w_\e \in L^1(d \mu_\e)$. 

Next, note that any $g \in C^\infty_c(\Rd)$, applying Lemma \ref{move mollifier prop} and the convergence of $\zeta_\e*\mu_\e$ to $\mu$ in $L^2(\Rd)$ gives
\begin{align*}
\int g w_\e d \mu_\e = \int \zeta_\e*(g \mu_\e) \zeta_\e \mu_\e = \int g (\zeta_\e*\mu_\e)^2 + C_\zeta \e \|\grad g\|_\infty \|\zeta_\e*\mu_\e\|_{L^2(\Rd)}^2  \to \int g \mu^2
\end{align*}
Thus, $w_\e \in L^1(d \mu_\e)$ converges weakly to $\mu \in L^1( d\mu)$ in the sense of Definition \ref{weakvaryingdef}. Furthermore, 
\[ \lim_{\e \to 0} \int |w_\e|^{m-1} d \mu_\e = (m-1) \lim_{e \to 0} \F^m_\e(\mu_\e) = (m-1) \F^m(\mu) = \int |\mu|^{m-1} d \mu,\]
so $w_\e$ converges strongly to $\mu$ in the sense of Definition \ref{weakvaryingdef}. Finally, since (\ref{extra assumptions b}) ensures that $\int |x|^{m-1} d \mu_\e$ is bounded uniformly in $\e$, we may apply Proposition \ref{AGSthm}, part (\ref{strongcty}) to conclude that for all $g \in C^\infty_c(\Rd)$,
\[ \lim_{\e \to 0} \int g |w_\e|^{m-1} d \mu_\e = \int g |\mu|^{m-1} d \mu . \]

Taking $g = \grad f$ and combining with equation (\ref{almostdone}), we obtain
\begin{align*}
\lim_{\e \to 0} \int f v_\e d \mu_\e = - \int \grad f \mu^m = \int f \grad (\mu^m).
\end{align*}
This completes the proof of equation (\ref{GFgoal1}) and gives the result.
\end{proof}
 
{\color{Aquamarine} Ideally, we also would like to show that if $\mu_\e(t)$ is the gradient flow of $E_\e$, then as $\e \to 0$, there is a convergent subsequence. However, given the strong assumptions we need to even get gamma convergence of the gradient flows, I think compactness is beyond the scope of the present work.}
%
%\begin{lem}\label{lem:compactness}
%	Let $\mu_\e\in AC^2([0,T],\P_2(\R^d))$ be a regularized gradient flow such that $(\mu_\e(0))_{\e>0}$ is a recovery sequence for $\mu_0\in\P_2(\R^d)$ with respect to $W_2$. Then there exists $\mu\in AC^2([0,T],\P_2(\R^d))$ such that $\mu_\e(t) \wto \mu(t)$ narrowly as $N\to\infty$ for all $t\in[0,T]$. Furthermore, Condition \ref{cond:md} holds.
%\end{lem}
%\begin{proof}
%	Fix $t\in [0,T]$ and consider $\delta>0$ that we choose later. Then, by Proposition \ref{relative sizes lemma},
%\be\label{eq:inequality-discrete}
%	E_\e(\mu_\e(t)) \geq -C_\delta -\delta M_2(\varphi_{\e/\sqrt{2}}*\mu_\e(t)).
%\ee
%Also,
%\begin{align*}
%	M_2(\varphi_{\e/\sqrt{2}}*\mu_\e(t)) &= \ird |x|^2 \varphi_{\e/\sqrt{2}}*\mu_\e(t,x) \,d x = \ird \varphi_{\e/\sqrt{2}}*|\cdot|^2(x) \,d\mu_\e(t,x)\\
%	& = \ird (|x|^2 + f_\e) \,d\mu_\e(t,x) = M_2(\mu_\e(t)) + f_\e,
%\end{align*}
%where $f_\e \to0$ as $\e\to0$. \comment{(Need to double-check this.)} Therefore, \eqref{eq:inequality-discrete} gives
%\be\label{eq:inequality-discrete2}
%	\textstyle{E_\e(\mu_\e(t)) \geq -C_\delta - \delta M_2(\mu_\e(t)) - \delta f_\e.}
%\ee
%Now, by integrating the regularized gradient flow \eqref{ctyeqn} by parts, we get
%\bes
%	\frac{d}{dt} M_2(\mu_\e(t)) = -2\int_{\R^d} x \cdot \grad \frac{\delta E_\e}{\delta \mu_\e}(t) \,d\mu_\e(t,x) \leq \int_{\R^d} \left| \frac{\delta E_\e}{\delta \mu_\e}(t) \right|^2 \,d\mu_\e(x,t) + M_2(\mu_\e(t)), 
%\ees
%where $\delta E_\e/\delta \mu_\e$ is defined as in \eqref{eq:var-derivative}. By the dissipation equality, we have
%\bes
%	\int_{\R^d} \left| \frac{\delta E_\e}{\delta \mu_\e}(t) \right|^2 \,d\mu_\e(x,t) = -\frac{d}{dt} E_\e(\mu_\e(t)),
%\ees
%which yields
%\bes
%	\frac{d}{dt} \left( e^{-t} M_2(\mu_\e(t)) \right) + e^{-t} \frac{d}{dt} E_\e(\mu_\e(t)) \leq 0.
%\ees
%Thus, integrating by parts,
%\begin{align*}
%	&e^{-t} M_2(\mu_\e(t)) - M_2(\mu_\e(0)) + \int_0^t e^{-s} \frac{d}{ds} E_\e(\mu_\e(s)) \,ds\\
%	&\phantom{{}={}}= e^{-t} M_2(\mu_\e(t)) - M_2(\mu_\e(0)) + e^{-t} E_\e(\mu_\e(t)) - E_\e(\mu_\e(0)) + \int_0^t e^{-s} E_\e(\mu_\e(s)) \,d s \leq 0.
%\end{align*}
%Since $E(\mu_0),M_2(\mu_0)<\infty$, and $(\mu_\e(0))_{\e>0}$ is a recovery sequence for $\mu_0$ with respect to $W_2$, we know there exist constants $E_0,M_0>0$ such that $E_\e(\mu_\e(0))\leq E_0$ and $M_2(\mu_\e(t)) \leq M_0$. Also, since $E_\e$ is a Lyapunov functional, $E_\e(\mu_\e(s)) \geq E(\mu_\e(t))$ for all $s\in[0,t]$. Therefore,
%\bes
%	M_2(\mu_\e(t)) \leq e^T (M_0+E_0) - e^tE_\e(\mu_\e(t)).
%\ees
%By \eqref{eq:inequality-discrete2}, we then get
%\bes
%	M_2(\mu_\e(t)) \leq e^T (M_0+E_0) + e^t(C_\delta + \delta M_2(\mu_\e(t)) + \delta f_\e) \leq e^T (M_0+E_0) + e^T(C_\delta + \delta M_2(\mu_\e(t)) + \delta f_\e).
%\ees
%Choose $\delta = e^{-T}/2$ to obtain
%\be\label{eq:bound-moment}
%	M_2(\mu_\e(t)) \leq 2e^T(M_0 + E_0 + C_{e^{-T}/2}) + \frac{f_\e}{2} \leq M_T,
%\ee
%for some constant $M_T > 0$. Also, by \eqref{eq:inequality-discrete2},
%\be\label{eq:bound-energy}
%	E_\e(\mu_\e(t)) \geq -C_\delta - \delta M_T - \delta f_\e \geq E_T,
%\ee
%for some constant $E_T$, for any choice of $\delta >0$.
%
%{\color{Aquamarine}  
%(To finish the argument, we need equi-continuity, which I am not sure how to obtain with our degenerate $\lambda$- convexity...) \textcolor{red}{Update: I think we have  solved this issue. }We now use the generalization of Arzel\`a-Ascoli theorem given in \cite[Proposition 3.3.1]{AGS}. To this end, we first show that the family $\{\mu_\e\}_{\e>0}$ is equi-continuous in time on $[0,T]$ with respect to $W_2$. By \eqref{eq:bound-energy}, we have
%\bes
%	W_2^2(\mu_\e(t),\mu_\e(\tau)) \leq 2(E_0 - E_T) |t-\tau| \quad \mbox{for all $t,\tau\in[0,T]$},
%\ees
%which is the equi-continuity. In order to apply \cite[Proposition 3.3.1]{AGS}, we now only need to show that $\{\mu_\e(t)\}_{\e>0}$ is narrowly sequentially compact; by Prohorov's theorem, this means to show that $\{\mu_\e(t)\}_{\e>0}$ is tight, uniformly in $t$, which in turn is implied by $(M_2(\mu_\e(t)))_{\e>0}$ being a sequence bounded uniformly in $\e$ and $t$, which is readily given by \eqref{eq:bound-moment}. Arzel\`a-Ascoli theorem then gives that there exists $\mu \in C([0,T],\P(\R))$, a continuous curve from $[0,T]$ to $\P(\R)$, such that $\mu_\e(t) \wto \mu(t)$ narrowly as $N\to\infty$ for all $t\in[0,T]$, up to a subsequence of $(\mu_\e(t))_{\e>0}$. We also have $\mu(t) \in \P_2(\R^d)$ for all $t\in[0,T]$.}
%
%We now show that actually $\mu\in AC^2([0,T],\P_2(\R^d))$ and that Condition \ref{cond:md} is true. The following argument is found in the proof of \cite[Theorem 5.6]{CraigTopaloglu}. We know that
%\bes
%	\int_0^t |\mu_\e'|(s)^2 \,d s = E_\e(\mu_\e(0)) - E_\e(\mu_\e(t)) \leq E_0 - E_T.
%\ees
%Then, up to a subsequence, $\lim_{\e\to0} \int_0^t |\mu_\e'|(s)^2 \,d s = C$, for some $C\geq0$ independent of $N$. Therefore, $|\mu_\e'|$ is bounded in $L^2([0,t])$, and so, up to a further subsequence, it is $L^2$-weakly convergent to some $v \in L^2([0,t])$. It is then also $L^1$-weakly convergent to $v$, so that
%\be\label{eq:L1}
%	\lim_{\e\to0} \int_{t_0}^{t_1} |\mu_\e'|(s) \,d s = \int_{t_0}^{t_1} v(s) \,d s \quad \mbox{for all $0\leq t_0\leq t_1 \leq T$}.
%\ee
%We also know that, by definition of the metric derivative and $\mu_\e$ being 2-absolutely continuous, 
%\bes
%	W_2(\mu_\e(t_0),\mu_\e(t_1)) \leq \int_{t_0}^{t_1} |\mu_\e'|(s) \,d s.
%\ees
%Then, by the narrow lower semi-continuity of $W_2$ and \eqref{eq:L1}, 
%\bes
%	W_2(\mu(t_0),\mu(t_1)) \leq \int_{t_0}^{t_1} v(s) \,d s.
%\ees
%Therefore $\mu \in AC^2([0,T],\P_2(\R^d))$ and, by \cite[Theorem 1.1.2]{AGS}, $|\mu'|(s) \leq v(s)$ for almost every $s \in [0,T]$. By the weak lower semi-continuity of the $L^2$-norm, this gives
%\bes
%	\liminf_{\e\to0} \int_0^t |\mu_\e'|(s)^2 \,d s = \lim_{\e\to0} \int_0^t |\mu_\e'|(s)^2 \,d s \geq \int_0^t v(s)^2 \,d s \geq \int_0^t |\mu'|(s)^2 \,d s,
%\ees
%which is Condition \ref{cond:md}.
%\end{proof}
%

\section{Numerical results}
%
%\subsection{The method}
%
%
%
%\begin{cor}[Discretization of $E_\epsilon$]
%Fix $X_i(0) \in \Rd$ and $m_i \geq 0$, for $i\in I$. The gradient flow of $E_\epsilon$ with initial data $\mu(0) = \sum_{i} \delta_{X_i(0)} m_i$ is given by $\mu(t) = \sum_i \delta_{X_i(t)} m_i$ where $X_i(t)$ solves the following system of ODEs
%\be\label{eq:ode}
%	\frac{d}{dt} X_i(t) = \sum_{k} \left(\frac{\grad \varphi_\e (X_i(t)-X_k(t))m_k}{\sum_{j} \varphi_\e(X_k(t)-X_j(t))m_j}\right) + \frac{\sum_{k} \grad \varphi_\e(X_i(t)-X_k(t)) m_k}{\sum_{j} \varphi_\e(X_i(t)-X_j(t)) m_j} .
%\ee
%\comment{The above equation is for $m =1$. We need to rewrite it for general $m$.}
%\end{cor}
%
%
%\subsection{Simulations}
%
%Fix $d=1$. Let $\mu \in \P_2(\R)$ be a continuum gradient flow at the final time $T$, and $\tilde \mu$ the approximation of the discrete gradient flow solution obtained by solving \eqref{eq:ode} at the final time step. Then we define the quadratic Wasserstein error by
%\bes
%	\mt{err} = W_2(\mu,\tilde\mu).
%\ees
%To compute this, one can use the one-dimensional pseudo-inverse definition of the quadratic Wasserstein distance. Let us write $X$ and $\tilde X$ the pseudo-inverses of the cumulative distributions of $\mu$ and $\tilde \mu$, respectively. Then
%\bes
%	\mt{err} = \left(\int_0^1 \left(X(\eta) - \tilde X(\eta)\right)^2 \,d\eta\right)^{1/2}.
%\ees
%We have, for all $i\in\{1,\dots,N\}$,
%\[
%	\tilde X(\eta) = X_i \quad \mbox{if $\eta \in [M_{i-1},M_i)$},
%\]
%with $M_i := \sum_{j=1}^{i} m_j$ and the convention $M_0 = 0$. Therefore
%\be \label{eq:error-wasserstein-1d-2}
%	\mt{err} = \left(\sum_{i=1}^N \int_{M_{i-1}}^{M_i} \left(X_i - X(\eta)\right)^2 \,d\eta\right)^{1/2}.
%\ee
%{\color{Aquamarine}  When the initial data of the gradient flow is a Gaussian and $E$ is the entropy, the integral in equation (\ref{eq:error-wasserstein-1d-2}) can be computed analytically.  }
%
%
%\begin{figure}[!ht]
%\centering
%	\subcaptionbox{The heat equation with $\e = 0.12$.\label{fig:heat-error}}{\includegraphics[scale=0.41]{./figures/error_heat_T08_e012.eps}}
%	\subcaptionbox{The porous medium equation with $m=2$ and $\e = 0.0035$.\label{fig:pm-error}}{\includegraphics[scale=0.41]{./figures/error_porous_T08_e0035.eps}}
%	\caption{The quadratic Wasserstein error as a function of $N$, with $\Delta t = 10^{-4}$.\label{fig:error}}
%\end{figure}
%
%\begin{figure}[!ht]
% {\includegraphics[scale=0.6]{LogLogError_Nx_Gaussian_081416.png}}
% %function and parameters: LogLogError(m=1,Nx_vec = array([10,50,100,500,1000,2000,3000,4000,5000]),Nt= 1000,t_vec = array([ 1.0]),eps_vec = array([.1]),rho0 = lambda x,y: gaussian(.5,x,y),dim=1)
%\caption{We compute the error between exact and approximate solutions to the one dimensional heat equation with initial data $\mu_0 = exp(x^2)/\sqrt{\pi}$ at time 1, with $\e = 0.1$. The quadratic Wasserstein error scales linearly with the number of particles. The line of best fit in the log-log plot has slope $-1.05$.}
%\end{figure}
%
%\begin{figure}[!ht]
%{\includegraphics[scale=0.5]{ExactVxApproximate_Gaussian_081416.png}}
%%BlobDiffusion(m = 1,Nx =500, Nt = 1000, snapshot_times = array([0,.25,.5]), eps = .1, rho0 = lambda x,y: gaussian(.5,x,y),dim = 1,PlotOrNot = 'Y')
% {\includegraphics[scale=0.5]{Error_time_Gaussian_081416.png}}
% %LogLogError(m=1,Nx_vec = array([500]),Nt= 1000,t_vec = array([0,.25,.5,1.0,1.5,2.0,3.0,5.0,7.0,10.0]),eps_vec = array([0.1]),rho0 = lambda x,y: gaussian(.5,x,y),dim=1)
% \caption{We compare  exact and approximate solutions to the one dimensional heat equation  at various times, with initial data $\mu_0 = exp(x^2)/\sqrt{\pi}$, 500 particles and $\e = 0.1$. In the left plot, we show the exact and approximate densities at times 0, 0.25, and 0.5. In the right plot, we show that the quadratic Wasserstein error increases as a function of time.}
%\end{figure}
%
%\subsection{Scaling of discretization and regularization}
%We now derive a relation between the regularization parameter $\e$ and the number of points $N$. Let $\mu_\e$ be a regularized gradient flow solution. By Lemma \ref{lem:compactness} and the convergence of the gradient flows, there exists $\mu$ such that $W_2(\mu_\e(t),\mu(t)) \to 0$ as $\e\to0$ for all $t\in(0,T]$, $\mu_\e(0) = \mu_0$ and $\mu$ is the continuum gradient flow solution. Let $\mu_\e^N$ be the empirical measure associated to the solution of \eqref{eq:ode} such that $\mu_\e^N(0) = \mu^N(0)$ and $W_2(\mu^N(0),\mu_0) \to 0$ as $N\to\infty$. Then, for all $t\in[0,T]$,
%\be\label{eq:tri}
%	W_2(\mu_\e^N(t),\mu(t)) \leq W_2(\mu_\e^N(t),\mu_\e(t)) + W_2(\mu_\e(t),\mu(t)).
%\ee
%Also, we know that
%\bes
%	W_2(\mu_\e^N(t),\mu_\e(t)) \leq e^{t/\e^2} W_2(\mu_\e^N(0),\mu_\e(0)) = e^{t/\e^2} W_2(\mu^N(0),\mu(0)).
%\ees
%We can choose $\mu^N(0)$ such that $W_2(\mu^N(0),\mu(0)) \leq CN^{-1/d}$ for some constant $C>0$. Then,
%\be\label{eq:Neps}
%	W_2(\mu_\e^N(t),\mu_\e(t)) \leq Ce^{T/\e^2} N^{-1/d}.
%\ee
%Therefore, since we want $W_2(\mu_\e^N(t),\mu(t)) \to0$ as $\e\to0$ and $N\to\infty$ for all $t\in[0,T]$, \eqref{eq:tri} and \eqref{eq:Neps} require that $Ce^{T/\e^2}N^{-1/d} \to 0$ as $\e\to0$ and $N\to\infty$. That is, we want
%\bes
%	e^{T/\e^2} = o(N^{1/d}).
%\ees
%For example, $e^{T/\e^2} = N^{\alpha/d}$ for $0< \alpha < 1$ is sufficient. In this case,
%\bes
%	T\e^{-2} = \alpha/d \log(N), \quad \mbox{or} \quad \e^2\log(N) = Td/\alpha.
%\ees
%{\color{Aquamarine}  
%\begin{remark}
%In Serfaty's scheme, I believe that the scaling relationship between $\epsilon$ and the number of particles will come from the fact that the initial data must be ``well-prepared'', i.e. $\lim_{\e \to 0} E_\e(\mu_\e(0)) = E(\mu(0))$. If $\mu_\e$ is a sum of Dirac masses on a grid, what relationship between $N$ and $\e$ is required for the left hand side to be bounded? \\ \\
%Suppose $\F^m_\e(\mu_\e) < C$ uniformly in $\epsilon$. If $\mu_\e$ is a sum of $N$ equally weighted Dirac masses, this implies,
%\begin{align*}
%\frac{1}{m-1} \sum_{i = 1}^N \left( \sum_{j=1}^N \varphi_\e(x_i-x_j)\frac{1}{N} \right)^{m-1} \frac{1}{N} = \F^m_\e(\mu_e) < C
%\end{align*}
%Taking only the $N$ elements of the sums where $i = j$, we obtain
%\[ \frac{1}{m-1}  \left(  \frac{\varphi(0)}{\epsilon^d N} \right)^{m-1}  < C .\]
%Therefore, we must have $\frac{1}{N} = O(\epsilon^d)$ or $\frac{1}{N^{1/d}} = O(\epsilon)$. Since $\frac{1}{N^{1/d}}$ is proportional to the spacing between the particles in $d$ dimensions, this heuristically says that the ``width of the blobs must be larger than the spacing between the particles'', as was the case in Katy and Andrea's work on the aggregation equation. (I think a similar argument could be made for the entropy.)
%\end{remark}}
%
%\section{Other things to try}
%\begin{enumerate}
%\item So far, we have only considered the case when $\varphi(x)$ is a Gaussian. Can we extend the previous arguments to more general mollifiers?
%\item Let's do the numerics in higher dimensions! Can we also do the error analysis in higher dimensions, at least in some special cases?
%\end{enumerate}

\bibliographystyle{plain}
\bibliography{HeightConstrainedAgg}

\end{document}